{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2a80fde4",
   "metadata": {},
   "source": [
    "# Tratamento inicial dos dados"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2d572f4",
   "metadata": {},
   "source": [
    "Objetivo:\n",
    "1. Carregar os dados;\n",
    "2. Selecionar as colunas que serão lidas;\n",
    "3. Fazer uma amostragem aleatória de 800.000 dados (~20% do dataset);\n",
    "4. Salvar em um novo ``.csv`` que seja mais leve"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6aa5348c",
   "metadata": {},
   "source": [
    "## Seleção de variáveis e amostragem dos dados"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d29c790",
   "metadata": {},
   "source": [
    "**NOTA SOBRE O RESULTADO DA LLM:** O algoritmo gerado para selecionar e amostrar os dados foi bastante satisfatório, a não ser por um pequeno erro lógico no final: na fase ``# junta tudo``, o código tenta tirar novamente 800_000 amostras de uma lista que já tem (teoricamente) 800_000 amostras, então essa amostragem não faz sentido. Na prática, ainda, o código provavelmente vai gerar um erro, já que nosso banco não tem exatamente 4M registros e o resultado terá um pouco menos que 800k amostras."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1db2a3f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\"\n",
    "GERA O ARQUIVO SAMPLE, NÃO RODAR SE O ARQUIVO JÁ ESTIVER CRIADO\n",
    "\"\"\"\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "\n",
    "# Configurações\n",
    "DATA_PATH = Path().resolve() / 'data'\n",
    "ARQUIVO_ORIGEM_PATH = DATA_PATH / 'raw' / 'microdados_enem_2023.csv'\n",
    "ARQUIVO_DESTINO_PATH = DATA_PATH / 'raw' / 'microdados_enem_2023_sample.csv'\n",
    "\n",
    "colunas_desejadas = [\n",
    "    'NU_INSCRICAO', 'TP_FAIXA_ETARIA', 'TP_SEXO', 'TP_ESTADO_CIVIL', 'TP_COR_RACA',\n",
    "    'TP_NACIONALIDADE', 'TP_ST_CONCLUSAO', 'TP_ANO_CONCLUIU', 'TP_ESCOLA', 'TP_ENSINO',\n",
    "    'IN_TREINEIRO', 'CO_MUNICIPIO_ESC', 'TP_DEPENDENCIA_ADM_ESC', 'TP_LOCALIZACAO_ESC',\n",
    "    'TP_SIT_FUNC_ESC', 'CO_MUNICIPIO_PROVA', 'TP_PRESENCA_CN', 'TP_PRESENCA_CH',\n",
    "    'TP_PRESENCA_LC', 'TP_PRESENCA_MT', 'CO_PROVA_CN', 'CO_PROVA_CH', 'CO_PROVA_LC',\n",
    "    'CO_PROVA_MT', 'NU_NOTA_CN', 'NU_NOTA_CH', 'NU_NOTA_LC', 'NU_NOTA_MT', 'TP_LINGUA',\n",
    "    'TP_STATUS_REDACAO', 'NU_NOTA_COMP1', 'NU_NOTA_COMP2', 'NU_NOTA_COMP3', 'NU_NOTA_COMP4',\n",
    "    'NU_NOTA_COMP5', 'NU_NOTA_REDACAO', 'Q001', 'Q002', 'Q006', 'Q025'\n",
    "]\n",
    "\n",
    "# Parâmetros\n",
    "tamanho_amostra_final = 800_000\n",
    "tamanho_arquivo_total = 4_000_000  # Aproximadamente\n",
    "frac_amostragem = tamanho_amostra_final / tamanho_arquivo_total\n",
    "\n",
    "# Leitura em chunks\n",
    "chunk_size = 500_000\n",
    "amostras = []\n",
    "\n",
    "for chunk in pd.read_csv(ARQUIVO_ORIGEM_PATH, usecols=colunas_desejadas, chunksize=chunk_size, sep=';', encoding='latin1'):\n",
    "    amostra_chunk = chunk.sample(frac=frac_amostragem, random_state=553)\n",
    "    amostras.append(amostra_chunk)\n",
    "\n",
    "# Junta tudo\n",
    "# amostra_final = pd.concat(amostras).sample(n=tamanho_amostra_final, random_state=42) # resultado da LLM\n",
    "amostra_final = pd.concat(amostras)\n",
    "\n",
    "# Salva no CSV\n",
    "amostra_final.to_csv(ARQUIVO_DESTINO_PATH, index=False)\n",
    "\n",
    "print(f\"Amostra salva em {ARQUIVO_DESTINO_PATH}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0baeb25",
   "metadata": {},
   "source": [
    "## Leitura eficiente do dataframe amostrado"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42e972de",
   "metadata": {},
   "source": [
    "**NOTA SOBRE O RESULTADO DA LLM:** Constroi um dicionário de dtypes de forma inteligente, mas: i) faz um ``col for col ...`` desnecessariamente em ``colunas_float``. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1601b93a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Configurações\n",
    "ARQUIVO_AMOSTRA_PATH = DATA_PATH / 'raw' / 'microdados_enem_2023_sample.csv'\n",
    "\n",
    "# Definição dos tipos\n",
    "colunas_float = [\n",
    "    'NU_NOTA_CN', 'NU_NOTA_CH', 'NU_NOTA_LC', 'NU_NOTA_MT',\n",
    "    'NU_NOTA_COMP1', 'NU_NOTA_COMP2', 'NU_NOTA_COMP3', 'NU_NOTA_COMP4',\n",
    "    'NU_NOTA_COMP5', 'NU_NOTA_REDACAO'\n",
    "]\n",
    "\n",
    "colunas_string = [\n",
    "    'NU_INSCRICAO', 'CO_MUNICIPIO_ESC', 'CO_MUNICIPIO_PROVA'\n",
    "]\n",
    "\n",
    "# Captura os nomes das colunas\n",
    "colunas = pd.read_csv(ARQUIVO_AMOSTRA_PATH, nrows=0, encoding='latin1').columns.tolist()\n",
    "\n",
    "# Preparar o dicionário de tipos\n",
    "dtypes = {}\n",
    "for col in colunas:\n",
    "    if col in colunas_float:\n",
    "        dtypes[col] = 'float32'\n",
    "    elif col in colunas_string:\n",
    "        dtypes[col] = 'string'\n",
    "    else:\n",
    "        dtypes[col] = 'category'\n",
    "\n",
    "# Leitura com tipos otimizados\n",
    "df = pd.read_csv(ARQUIVO_AMOSTRA_PATH, dtype=dtypes, encoding='latin1')\n",
    "\n",
    "# Informações para conferência\n",
    "print(\"=\"*40)\n",
    "print(f\"Memória usada: {df.memory_usage(deep=True).sum() / (1024 ** 2):.2f} MB\")\n",
    "print(f\"Quantidade de colunas: {df.shape[1]}\")\n",
    "print(f\"Quantidade de linhas: {df.shape[0]}\")\n",
    "print(\"=\"*40)\n",
    "\n",
    "# Tipos de dados\n",
    "print(\"\\nTipos de dados por coluna:\")\n",
    "print(df.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d976d7aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checagem de valores nulos\n",
    "print(\"\\nValores nulos por coluna:\")\n",
    "nulos = df.isnull().sum()\n",
    "percentual_nulos = (nulos / len(df)) * 100\n",
    "\n",
    "# Criando um dataframe com os valores absolutos e percentuais\n",
    "df_nulos = pd.DataFrame({\n",
    "    'Valores Nulos': nulos,\n",
    "    'Percentual Nulos (%)': percentual_nulos\n",
    "})\n",
    "\n",
    "# Exibindo o dataframe de nulos\n",
    "print(df_nulos)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "geo-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
