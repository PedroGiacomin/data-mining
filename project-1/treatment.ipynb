{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2a80fde4",
   "metadata": {},
   "source": [
    "# Tratamento inicial dos dados"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2d572f4",
   "metadata": {},
   "source": [
    "Objetivo:\n",
    "1. Carregar os dados;\n",
    "2. Selecionar as colunas que serão lidas;\n",
    "3. Fazer uma amostragem aleatória de 800.000 dados (~20% do dataset);\n",
    "4. Salvar em um novo ``.csv`` que seja mais leve"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6aa5348c",
   "metadata": {},
   "source": [
    "## Seleção de variáveis e amostragem dos dados"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d29c790",
   "metadata": {},
   "source": [
    "**NOTA SOBRE O RESULTADO DA LLM:** O algoritmo gerado para selecionar e amostrar os dados foi bastante satisfatório, a não ser por um pequeno erro lógico no final: na fase ``# junta tudo``, o código tenta tirar novamente 800_000 amostras de uma lista que já tem (teoricamente) 800_000 amostras, então essa amostragem não faz sentido. Na prática, ainda, o código provavelmente vai gerar um erro, já que nosso banco não tem exatamente 4M registros e o resultado terá um pouco menos que 800k amostras."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1db2a3f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\"\n",
    "GERA O ARQUIVO SAMPLE, NÃO RODAR SE O ARQUIVO JÁ ESTIVER CRIADO\n",
    "\"\"\"\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "\n",
    "# Configurações\n",
    "DATA_PATH = Path().resolve() / 'data'\n",
    "ARQUIVO_ORIGEM_PATH = DATA_PATH / 'raw' / 'microdados_enem_2023.csv'\n",
    "ARQUIVO_DESTINO_PATH = DATA_PATH / 'raw' / 'microdados_enem_2023_sample.csv'\n",
    "\n",
    "colunas_desejadas = [\n",
    "    'NU_INSCRICAO', 'TP_FAIXA_ETARIA', 'TP_SEXO', 'TP_ESTADO_CIVIL', 'TP_COR_RACA',\n",
    "    'TP_NACIONALIDADE', 'TP_ST_CONCLUSAO', 'TP_ANO_CONCLUIU', 'TP_ESCOLA', 'TP_ENSINO',\n",
    "    'IN_TREINEIRO', 'CO_MUNICIPIO_ESC', 'TP_DEPENDENCIA_ADM_ESC', 'TP_LOCALIZACAO_ESC',\n",
    "    'TP_SIT_FUNC_ESC', 'CO_MUNICIPIO_PROVA', 'TP_PRESENCA_CN', 'TP_PRESENCA_CH',\n",
    "    'TP_PRESENCA_LC', 'TP_PRESENCA_MT', 'CO_PROVA_CN', 'CO_PROVA_CH', 'CO_PROVA_LC',\n",
    "    'CO_PROVA_MT', 'NU_NOTA_CN', 'NU_NOTA_CH', 'NU_NOTA_LC', 'NU_NOTA_MT', 'TP_LINGUA',\n",
    "    'TP_STATUS_REDACAO', 'NU_NOTA_COMP1', 'NU_NOTA_COMP2', 'NU_NOTA_COMP3', 'NU_NOTA_COMP4',\n",
    "    'NU_NOTA_COMP5', 'NU_NOTA_REDACAO', 'Q001', 'Q002', 'Q006', 'Q025'\n",
    "]\n",
    "\n",
    "# Parâmetros\n",
    "tamanho_amostra_final = 800_000\n",
    "tamanho_arquivo_total = 4_000_000  # Aproximadamente\n",
    "frac_amostragem = tamanho_amostra_final / tamanho_arquivo_total\n",
    "\n",
    "# Leitura em chunks\n",
    "chunk_size = 500_000\n",
    "amostras = []\n",
    "\n",
    "for chunk in pd.read_csv(ARQUIVO_ORIGEM_PATH, usecols=colunas_desejadas, chunksize=chunk_size, sep=';', encoding='latin1'):\n",
    "    amostra_chunk = chunk.sample(frac=frac_amostragem, random_state=553)\n",
    "    amostras.append(amostra_chunk)\n",
    "\n",
    "# Junta tudo\n",
    "# amostra_final = pd.concat(amostras).sample(n=tamanho_amostra_final, random_state=42) # resultado da LLM\n",
    "amostra_final = pd.concat(amostras)\n",
    "\n",
    "# Salva no CSV\n",
    "amostra_final.to_csv(ARQUIVO_DESTINO_PATH, index=False)\n",
    "\n",
    "print(f\"Amostra salva em {ARQUIVO_DESTINO_PATH}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0baeb25",
   "metadata": {},
   "source": [
    "## Leitura eficiente do dataframe amostrado"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42e972de",
   "metadata": {},
   "source": [
    "**NOTA SOBRE O RESULTADO DA LLM:** Constroi um dicionário de dtypes de forma inteligente, mas: i) faz um ``col for col ...`` desnecessariamente em ``colunas_float``. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1601b93a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "\n",
    "# Configurações\n",
    "DATA_PATH = Path().resolve() / 'data'\n",
    "ARQUIVO_AMOSTRA_PATH = DATA_PATH / 'raw' / 'microdados_enem_2023_sample.csv'\n",
    "\n",
    "# Definição dos tipos\n",
    "colunas_float = [\n",
    "    'NU_NOTA_CN', 'NU_NOTA_CH', 'NU_NOTA_LC', 'NU_NOTA_MT',\n",
    "    'NU_NOTA_COMP1', 'NU_NOTA_COMP2', 'NU_NOTA_COMP3', 'NU_NOTA_COMP4',\n",
    "    'NU_NOTA_COMP5', 'NU_NOTA_REDACAO'\n",
    "]\n",
    "\n",
    "colunas_string = [\n",
    "    'NU_INSCRICAO', 'CO_MUNICIPIO_ESC', 'CO_MUNICIPIO_PROVA'\n",
    "]\n",
    "\n",
    "# Captura os nomes das colunas\n",
    "colunas = pd.read_csv(ARQUIVO_AMOSTRA_PATH, nrows=0, encoding='latin1').columns.tolist()\n",
    "\n",
    "# Preparar o dicionário de tipos\n",
    "dtypes = {}\n",
    "for col in colunas:\n",
    "    if col in colunas_float:\n",
    "        dtypes[col] = 'float32'\n",
    "    elif col in colunas_string:\n",
    "        dtypes[col] = 'string'\n",
    "    else:\n",
    "        dtypes[col] = 'category'\n",
    "\n",
    "# Leitura com tipos otimizados\n",
    "df = pd.read_csv(ARQUIVO_AMOSTRA_PATH, dtype=dtypes, encoding='latin1')\n",
    "\n",
    "# Informações para conferência\n",
    "print(\"=\"*40)\n",
    "print(f\"Memória usada: {df.memory_usage(deep=True).sum() / (1024 ** 2):.2f} MB\")\n",
    "print(f\"Quantidade de colunas: {df.shape[1]}\")\n",
    "print(f\"Quantidade de linhas: {df.shape[0]}\")\n",
    "print(\"=\"*40)\n",
    "\n",
    "# Tipos de dados\n",
    "print(\"\\nTipos de dados por coluna:\")\n",
    "print(df.dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be4433dc",
   "metadata": {},
   "source": [
    "## Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af8c3e2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checagem de valores nulos\n",
    "print(\"\\nAno que concluiu:\")\n",
    "nulos = df.isnull().sum()\n",
    "percentual_nulos = (nulos / len(df)) * 100\n",
    "\n",
    "\n",
    "tp_escola = df['TP_ANO_CONCLUIU'].value_counts(dropna=False)\n",
    "tp_escola_pct = df['TP_ANO_CONCLUIU'].value_counts(normalize=True, dropna=False) * 100\n",
    "\n",
    "resultado = pd.DataFrame({\n",
    "    'Frequência': tp_escola,\n",
    "    'Percentual (%)': tp_escola_pct.round(2)\n",
    "})\n",
    "\n",
    "print(resultado)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5df08137",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checagem de valores nulos\n",
    "print(\"\\nConclusão:\")\n",
    "nulos = df.isnull().sum()\n",
    "percentual_nulos = (nulos / len(df)) * 100\n",
    "\n",
    "\n",
    "tp_escola = df['TP_ST_CONCLUSAO'].value_counts(dropna=False)\n",
    "tp_escola_pct = df['TP_ST_CONCLUSAO'].value_counts(normalize=True, dropna=False) * 100\n",
    "\n",
    "resultado = pd.DataFrame({\n",
    "    'Frequência': tp_escola,\n",
    "    'Percentual (%)': tp_escola_pct.round(2)\n",
    "})\n",
    "\n",
    "print(resultado)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "851d38e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "filtro = df[df['TP_ANO_CONCLUIU'] == '0']\n",
    "grupo = filtro.groupby('TP_ST_CONCLUSAO', dropna=False)['NU_INSCRICAO']\n",
    "\n",
    "resultado = pd.DataFrame({\n",
    "    'Total': grupo.count()\n",
    "})\n",
    "\n",
    "resultado['Percentual (%)'] = (resultado['Total'] / resultado['Total'].sum() * 100).round(2)\n",
    "\n",
    "print(resultado)\n",
    "print(resultado['Total'].sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "487e053e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df['TP_ST_CONCLUSAO'] != '1'].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bdf8ac9",
   "metadata": {},
   "outputs": [],
   "source": [
    "tirou0 = df.NU_NOTA_CH[df.NU_NOTA_CH == 0].count()\n",
    "tirou_mais_q_0 = df.NU_NOTA_CH[df.NU_NOTA_CH > 0].count()\n",
    "total = df.NU_NOTA_CH.count()\n",
    "\n",
    "print(tirou0, '\\t', 100.0*tirou0/total)\n",
    "print(tirou_mais_q_0, '\\t', 100.0*tirou_mais_q_0/total)\n",
    "print(total, '\\t', 100.0*total/total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "376a0b40",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df.NU_NOTA_CH == 0].groupby('TP_PRESENCA_CH').count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "654e19fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Tabela cruzada entre duas colunas categóricas\n",
    "tabela = pd.crosstab(df['TP_ANO_CONCLUIU'], df['TP_ST_CONCLUSAO'][df['TP_ST_CONCLUSAO'] == 0])\n",
    "\n",
    "# Heatmap\n",
    "sns.heatmap(tabela, annot=True, fmt='d', cmap='Blues')\n",
    "plt.xlabel('COLUNA2')\n",
    "plt.ylabel('COLUNA1')\n",
    "plt.title('Heatmap entre COLUNA1 e COLUNA2')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d976d7aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checagem de valores nulos\n",
    "print(\"\\nValores nulos por coluna:\")\n",
    "nulos = df.isnull().sum()\n",
    "percentual_nulos = (nulos / len(df)) * 100\n",
    "\n",
    "# Criando um dataframe com os valores absolutos e percentuais\n",
    "df_nulos = pd.DataFrame({\n",
    "    'Valores Nulos': nulos,\n",
    "    'Percentual Nulos (%)': percentual_nulos\n",
    "})\n",
    "\n",
    "# Exibindo o dataframe de nulos\n",
    "print(df_nulos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef1cff36",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checagem de valores nulos\n",
    "print(\"\\nTipo de escola:\")\n",
    "\n",
    "tp_escola = df['TP_ESCOLA'].value_counts(dropna=False)\n",
    "tp_escola_pct = df['TP_ESCOLA'].value_counts(normalize=True, dropna=False) * 100\n",
    "\n",
    "resultado = pd.DataFrame({\n",
    "    'Frequência': tp_escola,\n",
    "    'Percentual (%)': tp_escola_pct.round(2)\n",
    "})\n",
    "\n",
    "print(resultado)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6687a0be",
   "metadata": {},
   "outputs": [],
   "source": [
    "median = df.NU_NOTA_MT.median() \n",
    "acima_da_mediana = df.NU_NOTA_MT[df.NU_NOTA_MT > median]\n",
    "\n",
    "df.groupby().agg({'NU_NOTA_MT': 'mean', 'SEXO': 'count'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41176861",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checagem de valores nulos\n",
    "print(\"\\nTipo de ensino:\")\n",
    "\n",
    "tp_escola = df['TP_ENSINO'].value_counts(dropna=False)\n",
    "tp_escola_pct = df['TP_ENSINO'].value_counts(normalize=True, dropna=False) * 100\n",
    "\n",
    "resultado = pd.DataFrame({\n",
    "    'Frequência': tp_escola,\n",
    "    'Percentual (%)': tp_escola_pct.round(2)\n",
    "})\n",
    "\n",
    "print(resultado)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "044acce0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checagem de valores nulos\n",
    "print(\"\\nPresença Mat:\")\n",
    "\n",
    "tp_escola = df['TP_PRESENCA_MT'].value_counts(dropna=False)\n",
    "tp_escola_pct = df['TP_PRESENCA_MT'].value_counts(normalize=True, dropna=False) * 100\n",
    "\n",
    "resultado = pd.DataFrame({\n",
    "    'Frequência': tp_escola,\n",
    "    'Percentual (%)': tp_escola_pct.round(2)\n",
    "})\n",
    "\n",
    "print(resultado)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7723cda",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checagem de valores nulos\n",
    "print(\"\\n:\")\n",
    "\n",
    "tp_escola = df['TP_PRESENCA_MT'].value_counts(dropna=False)\n",
    "tp_escola_pct = df['TP_PRESENCA_MT'].value_counts(normalize=True, dropna=False) * 100\n",
    "\n",
    "resultado = pd.DataFrame({\n",
    "    'Frequência': tp_escola,\n",
    "    'Percentual (%)': tp_escola_pct.round(2)\n",
    "})\n",
    "\n",
    "print(resultado)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8d45349",
   "metadata": {},
   "source": [
    "Abaixo, segue a análise descritiva da distribuição das notas por área de conhecimento. Foram plotados 5 histogramas, um para cada área de conhecimento. Como o histograma da redação tinha uma distribuição muito diferente dos demais, foi decidido plotá-lo separadamente dos outros.\n",
    "\n",
    "Percebe-se que a mediana está muito próxima da média, sugerindo uma distribuição simétrica. Destaca-se a presença de notas zeradas em todas as áreas do conhecimento. Esse comportamento é curioso e será objeto de investigação."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0ca2623",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(2, 2, figsize=(12, 8))\n",
    "colunas = ['NU_NOTA_CN', 'NU_NOTA_CH', 'NU_NOTA_LC', 'NU_NOTA_MT']\n",
    "titulos = ['Nota da prova de Ciências da Natureza',\n",
    "           'Nota da prova de Ciência Humanas',\n",
    "           'Nota da prova de Linguagens e Códigos',\n",
    "           'Nota da prova de Matemática']\n",
    "\n",
    "for ax, col, tit in zip(axes.flatten(), colunas, titulos):\n",
    "    sns.histplot(df[col], bins='auto', ax=ax)\n",
    "\n",
    "    media = df[col].mean()\n",
    "    std = df[col].std()\n",
    "    mediana = df[col].median()\n",
    "\n",
    "    ax.axvline(media, color='red', linestyle='--', linewidth=1.0, label='Média')\n",
    "    ax.axvline(mediana, color='blue', linestyle='--', linewidth=1.0, label='Mediana')\n",
    "    ax.axvline(media + std, color='orange', linestyle='--', linewidth=0.5, label='+1 desvio')\n",
    "    ax.axvline(media - std, color='orange', linestyle='--', linewidth=0.5, label='-1 desvio')\n",
    "    ax.axvline(media + 2*std, color='green', linestyle='--', linewidth=0.5, label='+2 desvios')\n",
    "    ax.axvline(media - 2*std, color='green', linestyle='--', linewidth=0.5, label='-2 desvios')\n",
    "\n",
    "    ax.set_title(f'Histograma \\n{tit}', fontsize=12)\n",
    "    ax.set_xlabel('Nota')\n",
    "    ax.set_ylabel('')\n",
    "    ax.set_xlim(-50, 1000)\n",
    "    ax.set_ylim(0, 8000)\n",
    "\n",
    "    if col == colunas[0]:\n",
    "        ax.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# Gráfico da Redação separado\n",
    "col = 'NU_NOTA_REDACAO'\n",
    "media = df[col].mean()\n",
    "std = df[col].std()\n",
    "mediana = df[col].median()\n",
    "\n",
    "plt.figure(figsize=(6, 4))\n",
    "sns.histplot(df[col], bins=50)\n",
    "\n",
    "plt.axvline(media, color='red', linestyle='--', linewidth=1.0, label='Média')\n",
    "plt.axvline(mediana, color='blue', linestyle='--', linewidth=1.0, label='Mediana')\n",
    "plt.axvline(media + std, color='orange', linestyle='--', linewidth=0.5, label='+1 desvio')\n",
    "plt.axvline(media - std, color='orange', linestyle='--', linewidth=0.5, label='-1 desvio')\n",
    "plt.axvline(media + 2*std, color='green', linestyle='--', linewidth=0.5, label='+2 desvios')\n",
    "plt.axvline(media - 2*std, color='green', linestyle='--', linewidth=0.5, label='-2 desvios')\n",
    "\n",
    "plt.title('Histograma \\nNota da prova de redação', fontsize=12)\n",
    "plt.xlabel('Nota')\n",
    "plt.ylabel('')\n",
    "plt.xlim(-50, 1000)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ac3260f",
   "metadata": {},
   "source": [
    "Abaixo, segue a análise descritiva da distribuição das notas por competência na prova de redação. Foram plotados 5 histogramas, um para cada competência.\n",
    "\n",
    "Percebe-se que a mediana está muito próxima da média, sugerindo uma distribuição simétrica. Destaca-se a presença de notas zeradas em todas as competências, como foi observado também para as notas das provas por área de conhecimento acima. Esse comportamento é curioso e será objeto de investigação também. ???"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e5ada05",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(3, 2, figsize=(12, 12))\n",
    "colunas = ['NU_NOTA_COMP1', 'NU_NOTA_COMP2', 'NU_NOTA_COMP3', 'NU_NOTA_COMP4', 'NU_NOTA_COMP5']\n",
    "titulos = ['Nota Competência 1 - Redação',\n",
    "           'Nota Competência 2 - Redação',\n",
    "           'Nota Competência 3 - Redação',\n",
    "           'Nota Competência 4 - Redação',\n",
    "           'Nota Competência 5 - Redação']\n",
    "\n",
    "for ax, col, tit in zip(axes.flatten(), colunas, titulos):\n",
    "    sns.histplot(df[col], bins=10, ax=ax)\n",
    "\n",
    "    media = df[col].mean()\n",
    "    std = df[col].std()\n",
    "    mediana = df[col].median()\n",
    "\n",
    "    ax.axvline(media, color='red', linestyle='--', linewidth=1.0, label='Média')\n",
    "    ax.axvline(mediana, color='blue', linestyle='--', linewidth=1.0, label='Mediana')\n",
    "    ax.axvline(media + std, color='orange', linestyle='--', linewidth=0.5, label='+1 desvio')\n",
    "    ax.axvline(media - std, color='orange', linestyle='--', linewidth=0.5, label='-1 desvio')\n",
    "    ax.axvline(media + 2*std, color='green', linestyle='--', linewidth=0.5, label='+2 desvios')\n",
    "    ax.axvline(media - 2*std, color='green', linestyle='--', linewidth=0.5, label='-2 desvios')\n",
    "\n",
    "    ax.set_title(f'Histograma \\n{tit}', fontsize=12)\n",
    "    ax.set_xlabel('Nota')\n",
    "    ax.set_ylabel('')\n",
    "    ax.set_xlim(0, 200) \n",
    "    ax.set_ylim(0, 250000)\n",
    "  \n",
    "    if col == colunas[0]:\n",
    "        ax.legend()\n",
    "\n",
    "# Remove o sexto subplot vazio (última célula da grade 2x3)\n",
    "if len(colunas) < len(axes.flatten()):\n",
    "    for ax in axes.flatten()[len(colunas):]:\n",
    "        fig.delaxes(ax)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c236a97",
   "metadata": {},
   "source": [
    "Com intuito de categorizar as variáveis numéricas notas (área de conhecimento e competencia da prova de redação) foram adotadas 5 faixas: ausente, zerou, baixa, media e alta. O critério de classificação das notas em cada uma das faixas foi:  \n",
    "\n",
    "1. ausente: valores NA do banco, que significa pessoas que não compareceram ou tiveram sua prova anulada no dia da prova da respectiva área de conhecimento.\n",
    "2. zerou: valor da nota igual a 0 (zero).\n",
    "3. baixa: valor da nota inferior a media - 1 desvio\n",
    "4. media: valor da nota entre a media - 1 desvio e media + 1 desvio\n",
    "5. alta: valor da nota superior a media + 1 desvio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26af2b8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transformacao das variáveis numéricas em categóricas, segunda as faixas estipuladas\n",
    "\n",
    "colunas = ['NU_NOTA_CN', 'NU_NOTA_CH', 'NU_NOTA_LC', 'NU_NOTA_MT', 'NU_NOTA_REDACAO', \n",
    "           'NU_NOTA_COMP1', 'NU_NOTA_COMP2', 'NU_NOTA_COMP3', 'NU_NOTA_COMP4', 'NU_NOTA_COMP5']\n",
    "\n",
    "for col in colunas:\n",
    "    media = df[col].mean()\n",
    "    std = df[col].std()\n",
    "\n",
    "    condicoes = [\n",
    "        df[col].isna(),\n",
    "        df[col] == 0,\n",
    "        df[col] < media - std,\n",
    "        df[col] <= media + std,\n",
    "        df[col] > media + std\n",
    "    ]\n",
    "\n",
    "    categorias = ['ausente', 'zerou', 'baixa', 'media', 'alta']\n",
    "\n",
    "    resultado = np.select(condicoes, categorias, default='erro')\n",
    "\n",
    "    df[col] = pd.Categorical(\n",
    "        resultado,\n",
    "        categories=['ausente', 'zerou', 'baixa', 'media', 'alta'],\n",
    "        ordered=True\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d9925c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Proporcao das faixas das notas\n",
    "\n",
    "print(\"\\n:\")\n",
    "\n",
    "colunas = ['NU_NOTA_CN', 'NU_NOTA_CH', 'NU_NOTA_LC', 'NU_NOTA_MT', 'NU_NOTA_REDACAO',\n",
    "           'NU_NOTA_COMP1', 'NU_NOTA_COMP2', 'NU_NOTA_COMP3', 'NU_NOTA_COMP4', 'NU_NOTA_COMP5']\n",
    "contagens = {}\n",
    "percentual = {}\n",
    "\n",
    "for col in colunas:\n",
    "    \n",
    "    contagens[f'tp_{col}'] = df[col].value_counts(dropna=False)\n",
    "    percentual[f'tp_{col}_pct'] = df[col].value_counts(normalize=True, dropna=False) * 100\n",
    "\n",
    "    resultado = pd.DataFrame({\n",
    "        'Frequência': contagens[f'tp_{col}'],\n",
    "        'Percentual (%)': percentual[f'tp_{col}_pct'].round(2)\n",
    "    })\n",
    "    \n",
    "    print(resultado, '\\n')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "geo-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
