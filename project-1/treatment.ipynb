{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2a80fde4",
   "metadata": {},
   "source": [
    "# Exploração e tratamento inicial dos dados"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2d572f4",
   "metadata": {},
   "source": [
    "**Objetivo:**\n",
    "1. Carregar os dados;\n",
    "2. Selecionar as colunas que serão lidas;\n",
    "3. Fazer uma amostragem aleatória de 800.000 dados (~20% do dataset);\n",
    "4. Salvar em um novo ``.csv`` que seja mais leve\n",
    "5. Fazer uma análise exploratória de cada feature;\n",
    "6. Transformação dos dados:  \n",
    "   a. Aglutinar features;  \n",
    "   b. Diminuir número de categorias;  \n",
    "   c. Dados numéricos -> categorizar em faixas;  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6aa5348c",
   "metadata": {},
   "source": [
    "## Seleção de variáveis e amostragem dos dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1db2a3f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\"\n",
    "GERA O ARQUIVO SAMPLE, NÃO RODAR SE O ARQUIVO JÁ ESTIVER CRIADO\n",
    "\"\"\"\n",
    "\n",
    "# import pandas as pd\n",
    "# import numpy as np\n",
    "# from pathlib import Path\n",
    "\n",
    "# # Configurações\n",
    "# DATA_PATH = Path().resolve() / 'data'\n",
    "# ARQUIVO_ORIGEM_PATH = DATA_PATH / 'raw' / 'microdados_enem_2023.csv'\n",
    "# ARQUIVO_DESTINO_PATH = DATA_PATH / 'raw' / 'microdados_enem_2023_sample.csv'\n",
    "\n",
    "# colunas_desejadas = [\n",
    "#     'NU_INSCRICAO', 'TP_FAIXA_ETARIA', 'TP_SEXO', 'TP_ESTADO_CIVIL', 'TP_COR_RACA',\n",
    "#     'TP_NACIONALIDADE', 'TP_ST_CONCLUSAO', 'TP_ANO_CONCLUIU', 'TP_ESCOLA', 'TP_ENSINO',\n",
    "#     'IN_TREINEIRO', 'CO_MUNICIPIO_ESC', 'TP_DEPENDENCIA_ADM_ESC', 'TP_LOCALIZACAO_ESC',\n",
    "#     'TP_SIT_FUNC_ESC', 'CO_MUNICIPIO_PROVA', 'TP_PRESENCA_CN', 'TP_PRESENCA_CH',\n",
    "#     'TP_PRESENCA_LC', 'TP_PRESENCA_MT', 'CO_PROVA_CN', 'CO_PROVA_CH', 'CO_PROVA_LC',\n",
    "#     'CO_PROVA_MT', 'NU_NOTA_CN', 'NU_NOTA_CH', 'NU_NOTA_LC', 'NU_NOTA_MT', 'TP_LINGUA',\n",
    "#     'TP_STATUS_REDACAO', 'NU_NOTA_COMP1', 'NU_NOTA_COMP2', 'NU_NOTA_COMP3', 'NU_NOTA_COMP4',\n",
    "#     'NU_NOTA_COMP5', 'NU_NOTA_REDACAO', 'Q001', 'Q002', 'Q006', 'Q025'\n",
    "# ]\n",
    "\n",
    "# # Parâmetros\n",
    "# tamanho_amostra_final = 800_000\n",
    "# tamanho_arquivo_total = 4_000_000  # Aproximadamente\n",
    "# frac_amostragem = tamanho_amostra_final / tamanho_arquivo_total\n",
    "\n",
    "# # Leitura em chunks\n",
    "# chunk_size = 500_000\n",
    "# amostras = []\n",
    "\n",
    "# for chunk in pd.read_csv(ARQUIVO_ORIGEM_PATH, usecols=colunas_desejadas, chunksize=chunk_size, sep=';', encoding='latin1'):\n",
    "#     amostra_chunk = chunk.sample(frac=frac_amostragem, random_state=553)\n",
    "#     amostras.append(amostra_chunk)\n",
    "\n",
    "# # Junta tudo\n",
    "# # amostra_final = pd.concat(amostras).sample(n=tamanho_amostra_final, random_state=42) # resultado da LLM\n",
    "# amostra_final = pd.concat(amostras)\n",
    "\n",
    "# # Salva no CSV\n",
    "# amostra_final.to_csv(ARQUIVO_DESTINO_PATH, index=False)\n",
    "\n",
    "# print(f\"Amostra salva em {ARQUIVO_DESTINO_PATH}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0baeb25",
   "metadata": {},
   "source": [
    "## Leitura eficiente do dataframe amostrado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1601b93a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "\n",
    "# Configurações\n",
    "DATA_PATH = Path().resolve() / 'data'\n",
    "ARQUIVO_AMOSTRA_PATH = DATA_PATH / 'raw' / 'microdados_enem_2023_sample.csv'\n",
    "\n",
    "# Definição dos tipos\n",
    "colunas_float = [\n",
    "    'NU_NOTA_CN', 'NU_NOTA_CH', 'NU_NOTA_LC', 'NU_NOTA_MT',\n",
    "    'NU_NOTA_COMP1', 'NU_NOTA_COMP2', 'NU_NOTA_COMP3', 'NU_NOTA_COMP4',\n",
    "    'NU_NOTA_COMP5', 'NU_NOTA_REDACAO'\n",
    "]\n",
    "\n",
    "colunas_string = [\n",
    "    'NU_INSCRICAO', 'CO_MUNICIPIO_ESC', 'CO_MUNICIPIO_PROVA'\n",
    "]\n",
    "\n",
    "# Captura os nomes das colunas\n",
    "colunas = pd.read_csv(ARQUIVO_AMOSTRA_PATH, nrows=0, encoding='latin1').columns.tolist()\n",
    "\n",
    "# Preparar o dicionário de tipos\n",
    "dtypes = {}\n",
    "for col in colunas:\n",
    "    if col in colunas_float:\n",
    "        dtypes[col] = 'float32'\n",
    "    elif col in colunas_string:\n",
    "        dtypes[col] = 'string'\n",
    "    else:\n",
    "        dtypes[col] = 'category'\n",
    "\n",
    "# Leitura com tipos otimizados\n",
    "df = pd.read_csv(ARQUIVO_AMOSTRA_PATH, dtype=dtypes, encoding='latin1')\n",
    "\n",
    "# Informações para conferência\n",
    "print(\"=\"*40)\n",
    "print(f\"Memória usada: {df.memory_usage(deep=True).sum() / (1024 ** 2):.2f} MB\")\n",
    "print(f\"Quantidade de colunas: {df.shape[1]}\")\n",
    "print(f\"Quantidade de linhas: {df.shape[0]}\")\n",
    "print(\"=\"*40)\n",
    "\n",
    "# Tipos de dados\n",
    "print(\"\\nTipos de dados por coluna:\")\n",
    "print(df.dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be4433dc",
   "metadata": {},
   "source": [
    "## Variáveis categóricas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f624366",
   "metadata": {},
   "source": [
    "### Análise de dados nulos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7faf995f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checagem de valores nulos\n",
    "print(\"\\nValores nulos por coluna:\")\n",
    "nulos = df.isnull().sum()\n",
    "percentual_nulos = (nulos / len(df)) * 100\n",
    "\n",
    "# Criando um dataframe com os valores absolutos e percentuais\n",
    "df_nulos = pd.DataFrame({\n",
    "    'Valores Nulos': nulos,\n",
    "    'Percentual Nulos (%)': percentual_nulos\n",
    "})\n",
    "\n",
    "# Exibindo o dataframe de nulos\n",
    "print(df_nulos)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42c49daf",
   "metadata": {},
   "source": [
    "Dessa análise, já decidimos descartar os dados:\n",
    "- ``CO_MUNICIPIO_ESC``                         \n",
    "- ``TP_DEPENDENCIA_ADM_ESC``                   \n",
    "- ``TP_LOCALIZACAO_ESC``                       \n",
    "- ``TP_SIT_FUNC_ESC``\n",
    "porque 75% dos seus valores são nulos                          "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2015e40e",
   "metadata": {},
   "source": [
    "### Dados demográficos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "252261f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Dicionários com rótulos traduzidos\n",
    "labels_dict = {\n",
    "    'TP_SEXO': {'M': 'Masculino', 'F': 'Feminino'},\n",
    "    'TP_ESTADO_CIVIL': {\n",
    "        '0': 'Não informado',\n",
    "        '1': 'Solteiro(a)',\n",
    "        '2': 'Casado(a)/União estável',\n",
    "        '3': 'Divorciado(a)/Separado(a)',\n",
    "        '4': 'Viúvo(a)'\n",
    "    },\n",
    "    'TP_COR_RACA': {\n",
    "        '0': 'Não declarado',\n",
    "        '1': 'Branca',\n",
    "        '2': 'Preta',\n",
    "        '3': 'Parda',\n",
    "        '4': 'Amarela',\n",
    "        '5': 'Indígena',\n",
    "        '6': 'Sem info'\n",
    "    },\n",
    "    'TP_NACIONALIDADE': {\n",
    "        '0': 'Não informado',\n",
    "        '1': 'Brasileiro(a)',\n",
    "        '2': 'Naturalizado',\n",
    "        '3': 'Estrangeiro(a)',\n",
    "        '4': 'Brasileiro nascido no exterior'\n",
    "    }\n",
    "}\n",
    "\n",
    "# Colunas a serem visualizadas\n",
    "colunas_plot = ['TP_SEXO', 'TP_ESTADO_CIVIL', 'TP_COR_RACA', 'TP_NACIONALIDADE']\n",
    "\n",
    "# Criar subplots\n",
    "fig, axes = plt.subplots(1, 4, figsize=(16, 5))\n",
    "\n",
    "for i, col in enumerate(colunas_plot):\n",
    "    # Frequência absoluta\n",
    "    freq_abs = df[col].value_counts().sort_index()\n",
    "    # Frequência relativa em %\n",
    "    freq_rel = (freq_abs / len(df)) * 100\n",
    "    labels = [labels_dict[col].get(valor, str(valor)) for valor in freq_abs.index]\n",
    "\n",
    "    axes[i].bar(labels, freq_abs.values, color='steelblue')\n",
    "    axes[i].set_title(f'{col}')\n",
    "\n",
    "    axes[i].set_xticklabels(labels, rotation=30, ha='right')\n",
    "    \n",
    "    # Adiciona os valores relativos em % em cima de cada barra\n",
    "    for j, val in enumerate(freq_abs.values):\n",
    "        axes[i].text(j, val + 50, f'{freq_rel.values[j]:.2f}%', ha='center', va='bottom', fontsize=10, color='black')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05064301",
   "metadata": {},
   "source": [
    "### Dados de faixa etária"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd9e98cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as plt\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Dicionários com rótulos traduzidos\n",
    "labels_dict = {'TP_FAIXA_ETARIA' : {\n",
    "    '1': \"Menor de 17 anos\",\n",
    "    '2': \"17 anos\",\n",
    "    '3': \"18 anos\",\n",
    "    '4': \"19 anos\",\n",
    "    '5': \"20 anos\",\n",
    "    '6': \"21 anos\",\n",
    "    '7': \"22 anos\",\n",
    "    '8': \"23 anos\",\n",
    "    '9': \"24 anos\",\n",
    "    '10': \"25 anos\",\n",
    "    '11': \"26–30 anos\",\n",
    "    '12': \"31–35 anos\",\n",
    "    '13': \"36–40 anos\",\n",
    "    '14': \"41–45 anos\",\n",
    "    '15': \"46–50 anos\",\n",
    "    '16': \"51–55 anos\",\n",
    "    '17': \"56–60 anos\",\n",
    "    '18': \"61–65 anos\",\n",
    "    '19': \"66–70 anos\",\n",
    "    '20': \"Maior de 70 anos\"\n",
    "    }\n",
    "}\n",
    "\n",
    "# Colunas a serem visualizadas\n",
    "colunas_plot = ['TP_FAIXA_ETARIA']\n",
    "col = 'TP_FAIXA_ETARIA'\n",
    "\n",
    "# Criar subplots\n",
    "fig, ax = plt.subplots(1, 1, figsize=(10, 5))\n",
    "\n",
    "# Frequência absoluta\n",
    "freq_abs = df[col].value_counts(dropna=False).sort_index(key=lambda x: x.astype(float))\n",
    "# Frequência relativa em %\n",
    "freq_rel = (freq_abs / len(df)) * 100\n",
    "\n",
    "labels = [labels_dict[col].get(valor, str(valor)) for valor in freq_abs.index]\n",
    "\n",
    "ax.bar(labels, freq_abs.values, color='steelblue')\n",
    "ax.set_title(f'{col}')\n",
    "\n",
    "ax.set_xticklabels(labels, rotation=45, ha='right')\n",
    "\n",
    "# Adiciona os valores relativos em % em cima de cada barra\n",
    "for j, val in enumerate(freq_abs.values):\n",
    "    ax.text(j, val + 50, f'{freq_rel.values[j]:.2f}%', ha='center', va='bottom', fontsize=10, color='black', rotation=30)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8742c6f8",
   "metadata": {},
   "source": [
    "Decidimos não utilizar os dados de \"Faixa etária\" porque nos dão uma informação muito parecida com aquela dos \"Dados de conclusão do Ensino Médio\". Como será mostrado a seguir, esses dados podem ser mais precisos ao nos dizer sobre a \"experiência escolar\" do candidato no contexto da realização da prova do ENEM."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3475fbea",
   "metadata": {},
   "source": [
    "### Dados de conclusão do Ensino Médio"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dac54eaf",
   "metadata": {},
   "source": [
    "Observando os resultados abaixo, percebemos que todos os candidatos que marcaram \"Não informado\" na variável ``TP_ANO_CONCLUIU`` podem ser incluídos em uma das categorias de ``TP_ST_CONCLUSAO``. Então, decidimos unir essas duas variaveis na variável ``TP_CONCLUSAO``."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fabc788",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nAno em que concluiu:\")\n",
    "\n",
    "tp_escola = df['TP_ANO_CONCLUIU'].value_counts(dropna=False).sort_index(key=lambda x: x.astype(int))\n",
    "tp_escola_pct = df['TP_ANO_CONCLUIU'].value_counts(normalize=True, dropna=False).sort_index(key=lambda x: x.astype(int)) * 100\n",
    "\n",
    "resultado = pd.DataFrame({\n",
    "    'Frequência': tp_escola[tp_escola.index],\n",
    "    'Percentual (%)': tp_escola_pct[tp_escola_pct.index].round(2)\n",
    "})\n",
    "\n",
    "print(resultado)\n",
    "\n",
    "print(\"\\nSituação de conclusão:\")\n",
    "\n",
    "st_conclusao = df['TP_ST_CONCLUSAO'].value_counts(dropna=False).sort_index(key=lambda x: x.astype(int))\n",
    "st_conclusao_pct = df['TP_ST_CONCLUSAO'].value_counts(normalize=True, dropna=False).sort_index(key=lambda x: x.astype(int)) * 100\n",
    "\n",
    "resultado = pd.DataFrame({\n",
    "    'Frequência': st_conclusao,\n",
    "    'Percentual (%)': st_conclusao_pct.round(2)\n",
    "})\n",
    "\n",
    "print(resultado)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88cb5003",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nDos que já concluíram, foi em qual ano:\")\n",
    "df[df['TP_ST_CONCLUSAO'] == '1'].TP_ANO_CONCLUIU.value_counts(dropna=False).sort_index(key=lambda x: x.astype(int))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "957716db",
   "metadata": {},
   "source": [
    "Ainda, como a quantidade de candidatos que já concluíram o Ensino Médio decresce à medida que se afastam do ano de 2023, decidimos aglutinar algumas dessas categorias."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5df08137",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nAno em que concluiu:\")\n",
    "\n",
    "tp_escola = df['TP_ANO_CONCLUIU'].value_counts(dropna=False).sort_index(key=lambda x: x.astype(int))\n",
    "tp_escola_pct = df['TP_ANO_CONCLUIU'].value_counts(normalize=True, dropna=False).sort_index(key=lambda x: x.astype(int)) * 100\n",
    "\n",
    "resultado = pd.DataFrame({\n",
    "    'Frequência': tp_escola,\n",
    "    'Percentual (%)': tp_escola_pct.round(2)\n",
    "})\n",
    "\n",
    "print(resultado)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "accb312b",
   "metadata": {},
   "source": [
    "Assim, é gerada uma nova variável ``TP_CONCLUSAO`` que une as informações dessas duas variáveis. Mais informações na seção 'Transformações' do notebook.\n",
    "- 1: EM concluído mas sem ano\n",
    "- 2: EM será concluído em 2023\n",
    "- 3: EM será concluído após 2023\n",
    "- 4: EM não cursado\n",
    "- 5: EM concluído em 2022\n",
    "- 6: EM concluído entre 2021 e 2018\n",
    "- 7: EM concluído entre 2017 e 2007\n",
    "- 8: EM concluído antes de 2007"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e365de8",
   "metadata": {},
   "source": [
    "### Dados da escola do Ensino Médio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b699c48e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['TP_ENSINO'].value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41176861",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as plt\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Dicionários com rótulos traduzidos\n",
    "labels_dict = {\n",
    "    'TP_ESCOLA': {'1': 'Não Respondeu', '2': 'Pública', '3': 'Privada'},\n",
    "    'IN_TREINEIRO': {'1': 'Sim', '0': 'Não'},\n",
    "    'TP_ENSINO':{'1.0': 'Regular', '2.0': 'Especial'} \n",
    "}\n",
    "\n",
    "# Colunas a serem visualizadas\n",
    "colunas_plot = ['TP_ESCOLA', 'TP_ENSINO', 'IN_TREINEIRO']\n",
    "\n",
    "# Criar subplots\n",
    "fig, axes = plt.subplots(1, 3, figsize=(12, 5))\n",
    "\n",
    "for i, col in enumerate(colunas_plot):\n",
    "    # Frequência absoluta\n",
    "    freq_abs = df[col].value_counts(dropna=False).sort_index()\n",
    "    # Frequência relativa em %\n",
    "    freq_rel = (freq_abs / len(df)) * 100\n",
    "    labels = [labels_dict[col].get(valor, str(valor)) for valor in freq_abs.index]\n",
    "\n",
    "    axes[i].bar(labels, freq_abs.values, color='steelblue')\n",
    "    axes[i].set_title(f'{col}')\n",
    "\n",
    "    axes[i].set_xticklabels(labels, rotation=30, ha='right')\n",
    "    \n",
    "    # Adiciona os valores relativos em % em cima de cada barra\n",
    "    for j, val in enumerate(freq_abs.values):\n",
    "        axes[i].text(j, val + 50, f'{freq_rel.values[j]:.2f}%', ha='center', va='bottom', fontsize=10, color='black')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03fd6e6f",
   "metadata": {},
   "source": [
    "A partir dos dados da escola em que o candidato cursou o Ensino Médio, podemos perceber que a maior parte dos dados é inexistente. Todavia, manteremos essas variáveis na modelagem pois pode ser possível encontrar padrões interessantes para os usuários que não responderam. \n",
    "\n",
    "Como há uma quantidade muito pequena de dados com ``TP_ENSINO`` da categoria 'Especial', não vamos considerar essa variável no algoritmo de mineração de padrões"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ebfe0b0",
   "metadata": {},
   "source": [
    "### Dados do município de aplicação"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cfab579",
   "metadata": {},
   "source": [
    "Os dados da escola onde o candidato tem muitos valores nulos como pode ser visto na seção \"Dados nulos (geral)\", por isso não serão usados na modelagem.\n",
    "\n",
    "Uma proxy para localizaão será a região onde o candidato realizou a prova, que pode ser extraída da variável ``CO_MUNICIPIO_PROVA``."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "072a500f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['CO_MUNICIPIO_PROVA'].head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b99f4f5",
   "metadata": {},
   "source": [
    "Sabemos que o primeiro dígito corresponde à região, mas não sabemos qual é qual. Para isso investigaremos uma parte do arquivo original pra descobrir qual dígito corresponde a qual região do Brasil."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48d6601a",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = Path().resolve() / 'data'\n",
    "ARQUIVO_ORIGEM_PATH = DATA_PATH / 'raw' / 'microdados_enem_2023.csv'\n",
    "regiao = pd.read_csv(ARQUIVO_ORIGEM_PATH, encoding='latin1', nrows=1000, usecols=['CO_MUNICIPIO_PROVA', 'CO_UF_PROVA', 'SG_UF_PROVA'],\n",
    "                     delimiter=';')\n",
    "regiao.groupby(by='CO_UF_PROVA').first()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e43060f",
   "metadata": {},
   "source": [
    "Portanto, nosso mapeamento é:\n",
    "- 1: Norte\n",
    "- 2: Nordeste\n",
    "- 3: Sudeste\n",
    "- 4: Sul\n",
    "- 5: Centro-Oeste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "892a3231",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['REGIAO'] = df['CO_MUNICIPIO_PROVA'].apply(lambda x: x[0])\n",
    "df['REGIAO'] = df['REGIAO'].astype('category')\n",
    "df['REGIAO'].value_counts(normalize=True, dropna=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad89f38f",
   "metadata": {},
   "source": [
    "Portanto, temos dados para todas as regiões do Brasil, e da pra ver que a maior parte dos candidatos é do Nordeste, seguidos pelo Sudeste."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3b24353",
   "metadata": {},
   "source": [
    "### Dados de presença nas provas objetivas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd8322a1",
   "metadata": {},
   "source": [
    "A presença nas provas pode ser resumida a:\n",
    "- Presença no primeiro dia: CH e LC\n",
    "- Presença no segundo dia: CN e MT\n",
    "\n",
    "Para mostrar que as variáveis ``TP_PRESENCA_CH`` e ``TP_PRESENCA_LC`` são correspondentes, e ``TP_PRESENCA_CN`` e ``TP_PRESENCA_MT`` também, plotamos uma matriz de coocorrência"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db07a867",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Tabelas de coocorrência\n",
    "cont_mt_cn = pd.crosstab(df['TP_PRESENCA_MT'], df['TP_PRESENCA_CN'])\n",
    "cont_ch_lc = pd.crosstab(df['TP_PRESENCA_CH'], df['TP_PRESENCA_LC'])\n",
    "\n",
    "# Criar a figura com subplots lado a lado\n",
    "fig, axes = plt.subplots(1, 2, figsize=(10, 5))  # 5x10 total (altura x largura)\n",
    "\n",
    "# Heatmap 1: MT vs CN\n",
    "axes[0].imshow(cont_mt_cn, cmap='Blues', aspect='auto')\n",
    "axes[0].set_title('TP_PRESENCA_MT x TP_PRESENCA_CN')\n",
    "axes[0].set_xlabel('TP_PRESENCA_CN')\n",
    "axes[0].set_ylabel('TP_PRESENCA_MT')\n",
    "axes[0].set_xticks(range(len(cont_mt_cn.columns)))\n",
    "axes[0].set_xticklabels(cont_mt_cn.columns)\n",
    "axes[0].set_yticks(range(len(cont_mt_cn.index)))\n",
    "axes[0].set_yticklabels(cont_mt_cn.index)\n",
    "\n",
    "# Adiciona valores no heatmap 1\n",
    "for i in range(cont_mt_cn.shape[0]):\n",
    "    for j in range(cont_mt_cn.shape[1]):\n",
    "        axes[0].text(j, i, cont_mt_cn.values[i, j], ha='center', va='center', color='black')\n",
    "\n",
    "# Heatmap 2: CH vs LC\n",
    "axes[1].imshow(cont_ch_lc, cmap='Greens', aspect='auto')\n",
    "axes[1].set_title('TP_PRESENCA_CH x TP_PRESENCA_LC')\n",
    "axes[1].set_xlabel('TP_PRESENCA_LC')\n",
    "axes[1].set_ylabel('TP_PRESENCA_CH')\n",
    "axes[1].set_xticks(range(len(cont_ch_lc.columns)))\n",
    "axes[1].set_xticklabels(cont_ch_lc.columns)\n",
    "axes[1].set_yticks(range(len(cont_ch_lc.index)))\n",
    "axes[1].set_yticklabels(cont_ch_lc.index)\n",
    "\n",
    "# Adiciona valores no heatmap 2\n",
    "for i in range(cont_ch_lc.shape[0]):\n",
    "    for j in range(cont_ch_lc.shape[1]):\n",
    "        axes[1].text(j, i, cont_ch_lc.values[i, j], ha='center', va='center', color='black')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0200bae",
   "metadata": {},
   "source": [
    "### Dados do tipo de língua e do status da redação"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa020ac6",
   "metadata": {},
   "source": [
    "Apenas para entender a quantidade de pessoas que escolheu inglês ou espanhol, e também quantas pessoas tiveram alguma intercorrência na redação."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10f42bdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as plt\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Dicionários com rótulos traduzidos\n",
    "labels_dict = {\n",
    "    'TP_LINGUA': {'0': 'Inglês', '1': 'Espanhol'},\n",
    "    'TP_STATUS_REDACAO': {'1.0': 'Sem problemas',\n",
    "        '2.0': 'Anulada',\n",
    "        '3.0': 'Cópia Texto Motivador',\n",
    "        '4.0': 'Em Branco',\n",
    "        '6.0': 'Fuga ao tema',\n",
    "        '7.0': 'Não atendimento ao tipo textual',\n",
    "        '8.0': 'Texto insuficiente',\n",
    "        '9.0': 'Parte desconectada' \n",
    "    }\n",
    "}\n",
    "\n",
    "# Colunas a serem visualizadas\n",
    "colunas_plot = ['TP_LINGUA', 'TP_STATUS_REDACAO']\n",
    "\n",
    "# Criar subplots\n",
    "fig, axes = plt.subplots(1, 2, figsize=(12, 5))\n",
    "\n",
    "for i, col in enumerate(colunas_plot):\n",
    "    # Frequência absoluta\n",
    "    freq_abs = df[col].value_counts(dropna=False).sort_index()\n",
    "    # Frequência relativa em %\n",
    "    freq_rel = (freq_abs / len(df)) * 100\n",
    "    labels = [labels_dict[col].get(valor, str(valor)) for valor in freq_abs.index]\n",
    "\n",
    "    axes[i].bar(labels, freq_abs.values, color='steelblue')\n",
    "    axes[i].set_title(f'{col}')\n",
    "\n",
    "    axes[i].set_xticklabels(labels, rotation=30, ha='right')\n",
    "    \n",
    "    # Adiciona os valores relativos em % em cima de cada barra\n",
    "    for j, val in enumerate(freq_abs.values):\n",
    "        axes[i].text(j, val + 50, f'{freq_rel.values[j]:.2f}%', ha='center', va='bottom', fontsize=10, color='black')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e47ed86f",
   "metadata": {},
   "source": [
    "Ainda, a quantidade de redações com tipo ``nan`` é a quantidade de ausências + eliminados do dia 1. Ou seja, os valores nulos em ``TP_STATUS_REDACAO`` correspondem aos candidatos ausentes ou eleiminados da redação."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b4e1479",
   "metadata": {},
   "outputs": [],
   "source": [
    "ausencias_dia1 = df['TP_PRESENCA_CH'][df['TP_PRESENCA_CH'] != '1'].count()\n",
    "redacoes_nulas = df['TP_STATUS_REDACAO'].isna().sum()\n",
    "\n",
    "print(f'Ausentes e eliminados do dia 1: {ausencias_dia1}')\n",
    "print(f'Valores Nan em TIPO_STATUS_REDACAO: {redacoes_nulas}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e400e09d",
   "metadata": {},
   "source": [
    "### Dados dos tipos de prova"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be8c0588",
   "metadata": {},
   "source": [
    "Da cor do caderno de provas, pode-se inferir se a prova tem alguma adaptação. \n",
    "- Sabemos, a priori, que os cadernos de CN e MT são iguais, bem como os cadernos de CH e LC, por isso não plotaremos todos.\n",
    "- Sabemos, também, que valores nulos nos códigos de caderno correspondem a candidatos ausentes naquele dia."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67778cab",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as plt\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Dicionários com rótulos traduzidos\n",
    "labels_dict = {\n",
    "    'CO_PROVA_LC' : {\n",
    "        '1201.0': \"Azul\",\n",
    "        '1202.0': \"Amarela\",\n",
    "        '1203.0': \"Rosa\",\n",
    "        '1204.0': \"Branca\",\n",
    "        '1205.0': \"Rosa - Ampliada\",\n",
    "        '1206.0': \"Rosa - Superampliada\",\n",
    "        '1207.0': \"Laranja - Braile\",\n",
    "        '1208.0': \"Laranja - Adaptada Ledor\",\n",
    "        '1209.0': \"Verde - Videoprova - Libras\",\n",
    "        '1281.0': \"Azul (Reaplicação)\",\n",
    "        '1282.0': \"Amarela (Reaplicação)\",\n",
    "        '1283.0': \"Rosa (Reaplicação)\",\n",
    "        '1284.0': \"Branca (Reaplicação)\"\n",
    "    },\n",
    "    'CO_PROVA_CN': {\n",
    "        '1221.0': \"Azul\",\n",
    "        '1222.0': \"Amarela\",\n",
    "        '1223.0': \"Rosa\",\n",
    "        '1224.0': \"Cinza\",\n",
    "        '1225.0': \"Rosa - Ampliada\",\n",
    "        '1226.0': \"Rosa - Superampliada\",\n",
    "        '1227.0': \"Laranja - Braile\",\n",
    "        '1228.0': \"Laranja - Adaptada Ledor\",\n",
    "        '1229.0': \"Verde - Videoprova - Libras\",\n",
    "        '1301.0': \"Azul (Reaplicação)\",\n",
    "        '1302.0': \"Amarela (Reaplicação)\",\n",
    "        '1303.0': \"Cinza (Reaplicação)\",\n",
    "        '1304.0': \"Rosa (Reaplicação)\"\n",
    "    }\n",
    "}\n",
    "\n",
    "# Colunas a serem visualizadas\n",
    "colunas_plot = ['CO_PROVA_LC', 'CO_PROVA_CN']\n",
    "\n",
    "# Criar subplots\n",
    "fig, axes = plt.subplots(1, 2, figsize=(12, 6))\n",
    "\n",
    "for i, col in enumerate(colunas_plot):\n",
    "    # Frequência absoluta\n",
    "    freq_abs = df[col].value_counts(dropna=False).sort_index()\n",
    "    # Frequência relativa em %\n",
    "    # freq_rel = (freq_abs / len(df)) * 100\n",
    "    labels = [labels_dict[col].get(valor, str(valor)) for valor in freq_abs.index]\n",
    "\n",
    "    axes[i].bar(labels, freq_abs.values, color='steelblue')\n",
    "    axes[i].set_title(f'{col}')\n",
    "\n",
    "    axes[i].set_xticklabels(labels, rotation=30, ha='right')\n",
    "    \n",
    "    # Adiciona os valores relativos em % em cima de cada barra\n",
    "    for j, val in enumerate(freq_abs.values):\n",
    "        axes[i].text(j, val + 50, f'{freq_abs.values[j]}', ha='center', va='bottom', fontsize=10, color='black', rotation=45)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8464fca",
   "metadata": {},
   "source": [
    "Apesar de haver poucos valores pra provas adaptadas, extrair essa informação pode ser interessante para encontrar algum padrão."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "750fe02c",
   "metadata": {},
   "source": [
    "Pra confirmar que os cadernos são iguais para CN e MT, CH e LC, fazemos um crosstab. Essa pequena diferença vista em CH e LC se dá pelo fato de os códigos serem trocados para as provas \"Branca\" e \"Rosa\", e \"Branca (Reaplicação)\" e \"Rosa (Reaplicação)\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ec40b92",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Tabelas de coocorrência\n",
    "cont_mt_cn = pd.crosstab(df['CO_PROVA_MT'], df['CO_PROVA_CN'])\n",
    "cont_ch_lc = pd.crosstab(df['CO_PROVA_CH'], df['CO_PROVA_LC'])\n",
    "\n",
    "# Criar a figura com subplots lado a lado\n",
    "fig, axes = plt.subplots(1, 2, figsize=(10, 5))  # 5x10 total (altura x largura)\n",
    "\n",
    "# Heatmap 1: MT vs CN\n",
    "axes[0].imshow(cont_mt_cn, cmap='Blues', aspect='auto')\n",
    "axes[0].set_title('CO_PROVA_MT x CO_PROVA_CN')\n",
    "axes[0].set_xlabel('CO_PROVA_CN')\n",
    "axes[0].set_ylabel('CO_PROVA_MT')\n",
    "axes[0].set_xticks(range(len(cont_mt_cn.columns)))\n",
    "axes[0].set_xticklabels(cont_mt_cn.columns)\n",
    "axes[0].set_yticks(range(len(cont_mt_cn.index)))\n",
    "axes[0].set_yticklabels(cont_mt_cn.index)\n",
    "\n",
    "# Adiciona valores no heatmap 1\n",
    "for i in range(cont_mt_cn.shape[0]):\n",
    "    for j in range(cont_mt_cn.shape[1]):\n",
    "        axes[0].text(j, i, cont_mt_cn.values[i, j], ha='center', va='center', color='black')\n",
    "\n",
    "# Heatmap 2: CH vs LC\n",
    "axes[1].imshow(cont_ch_lc, cmap='Greens', aspect='auto')\n",
    "axes[1].set_title('CO_PROVA_CH x CO_PROVA_LC')\n",
    "axes[1].set_xlabel('CO_PROVA_LC')\n",
    "axes[1].set_ylabel('CO_PROVA_CH')\n",
    "axes[1].set_xticks(range(len(cont_ch_lc.columns)))\n",
    "axes[1].set_xticklabels(cont_ch_lc.columns)\n",
    "axes[1].set_yticks(range(len(cont_ch_lc.index)))\n",
    "axes[1].set_yticklabels(cont_ch_lc.index)\n",
    "\n",
    "# Adiciona valores no heatmap 2\n",
    "for i in range(cont_ch_lc.shape[0]):\n",
    "    for j in range(cont_ch_lc.shape[1]):\n",
    "        axes[1].text(j, i, cont_ch_lc.values[i, j], ha='center', va='center', color='black')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9175e647",
   "metadata": {},
   "source": [
    "### Dados socioeconômicos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e505529",
   "metadata": {},
   "source": [
    "Primeiro os dados de escolaridade da mãe e do pai."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a58ed10",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as plt\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Dicionários com rótulos traduzidos\n",
    "labels_dict = {\n",
    "    'Q001': {\n",
    "        \"Title\": 'Escolaridade do pai', \n",
    "        \"A\": \"Nunca estudou\",\n",
    "        \"B\": \"Até 4ª série/5º ano\",\n",
    "        \"C\": \"Até 8ª série/9º ano\",\n",
    "        \"D\": \"Até Ensino Médio\",\n",
    "        \"E\": \"Ensino Médio completo\",\n",
    "        \"F\": \"Faculdade completa\",\n",
    "        \"G\": \"Pós-graduação\",\n",
    "        \"H\": \"Não sabe\"\n",
    "    },\n",
    "\n",
    "    'Q002': {    \n",
    "        \"Title\": 'Escolaridade da mãe', \n",
    "        \"A\": \"Nunca estudou\",\n",
    "        \"B\": \"Até 4ª série/5º ano\",\n",
    "        \"C\": \"Até 8ª série/9º ano\",\n",
    "        \"D\": \"Até Ensino Médio\",\n",
    "        \"E\": \"Ensino Médio completo\",\n",
    "        \"F\": \"Faculdade completa\",\n",
    "        \"G\": \"Pós-graduação\",\n",
    "        \"H\": \"Não sabe\"\n",
    "    }\n",
    "}\n",
    "\n",
    "\n",
    "# Colunas a serem visualizadas\n",
    "colunas_plot = ['Q001', 'Q002']\n",
    "\n",
    "# Criar subplots\n",
    "fig, axes = plt.subplots(1, 2, figsize=(12, 6))\n",
    "\n",
    "for i, col in enumerate(colunas_plot):\n",
    "    # Frequência absoluta\n",
    "    freq_abs = df[col].value_counts(dropna=False).sort_index()\n",
    "    # Frequência relativa em %\n",
    "    # freq_rel = (freq_abs / len(df)) * 100\n",
    "    labels = [labels_dict[col].get(valor, str(valor)) for valor in freq_abs.index]\n",
    "\n",
    "    axes[i].bar(labels, freq_abs.values, color='steelblue')\n",
    "    axes[i].set_title(f\"{labels_dict[col]['Title']}\")\n",
    "\n",
    "    axes[i].set_xticklabels(labels, rotation=30, ha='right')\n",
    "\n",
    "    # Adiciona os valores relativos em % em cima de cada barra\n",
    "    freq_rel = (freq_abs / len(df)) * 100\n",
    "    for j, val in enumerate(freq_abs.values):\n",
    "        axes[i].text(j, val + 50, f'{freq_rel.values[j]:.2f}%', ha='center', va='bottom', fontsize=10, color='black')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2041d97f",
   "metadata": {},
   "source": [
    "Agora dados de renda familiar e internet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4654b0d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as plt\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Dicionários com rótulos traduzidos\n",
    "labels_dict = {\n",
    "    'Q006': {\n",
    "        \"Title\": 'Renda Familiar',\n",
    "        \"A\": \"Nenhuma Renda\",\n",
    "        \"B\": \"Até R$ 1.320,00\",\n",
    "        \"C\": \"R$ 1.320,01 – R$ 1.980,00\",\n",
    "        \"D\": \"R$ 1.980,01 – R$ 2.640,00\",\n",
    "        \"E\": \"R$ 2.640,01 – R$ 3.300,00\",\n",
    "        \"F\": \"R$ 3.300,01 – R$ 3.960,00\",\n",
    "        \"G\": \"R$ 3.960,01 – R$ 5.280,00\",\n",
    "        \"H\": \"R$ 5.280,01 – R$ 6.600,00\",\n",
    "        \"I\": \"R$ 6.600,01 – R$ 7.920,00\",\n",
    "        \"J\": \"R$ 7.920,01 – R$ 9.240,00\",\n",
    "        \"K\": \"R$ 9.240,01 – R$ 10.560,00\",\n",
    "        \"L\": \"R$ 10.560,01 – R$ 11.880,00\",\n",
    "        \"M\": \"R$ 11.880,01 – R$ 13.200,00\",\n",
    "        \"N\": \"R$ 13.200,01 – R$ 15.840,00\",\n",
    "        \"O\": \"R$ 15.840,01 – R$ 19.800,00\",\n",
    "        \"P\": \"R$ 19.800,01 – R$ 26.400,00\",\n",
    "        \"Q\": \"Acima de R$ 26.400,00\"\n",
    "    },\n",
    "    'Q025': {    \n",
    "        \"Title\": 'Acesso à internet', \n",
    "        \"A\": \"Não\",\n",
    "        \"B\": \"Sim\"\n",
    "    }\n",
    "}\n",
    "\n",
    "\n",
    "# Colunas a serem visualizadas\n",
    "colunas_plot = ['Q006', 'Q025']\n",
    "\n",
    "# Criar subplots\n",
    "fig, axes = plt.subplots(1, 2, figsize=(12, 6))\n",
    "\n",
    "for i, col in enumerate(colunas_plot):\n",
    "    # Frequência absoluta\n",
    "    freq_abs = df[col].value_counts(dropna=False).sort_index()\n",
    "    # Frequência relativa em %\n",
    "    # freq_rel = (freq_abs / len(df)) * 100\n",
    "    labels = [labels_dict[col].get(valor, str(valor)) for valor in freq_abs.index]\n",
    "\n",
    "    axes[i].bar(labels, freq_abs.values, color='steelblue')\n",
    "    axes[i].set_title(f\"{labels_dict[col]['Title']}\")\n",
    "\n",
    "    axes[i].set_xticklabels(labels, rotation=45, ha='right')\n",
    "\n",
    "    # Adiciona os valores relativos em % em cima de cada barra\n",
    "    freq_rel = (freq_abs / len(df)) * 100\n",
    "    for j, val in enumerate(freq_abs.values):\n",
    "        axes[i].text(j, val + 50, f'{freq_rel.values[j]:.2f}%', ha='center', va='bottom', fontsize=10, color='black', rotation=30)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97388da9",
   "metadata": {},
   "source": [
    "Para diminuir a quanutidade de categorias, vamos aglutinar alguns valores possíveis de variáveis de renda.\n",
    "\n",
    "- 0: Nenhuma renda\n",
    "- 1: Renda até 1 Salário Mínimo\n",
    "- 2: Renda até 2 Salários Mínimos\n",
    "- 3: Renda até 3 Salários Mínimos\n",
    "- 4: Renda até 4 Salários Mínimos\n",
    "- 5: Renda até 6 Salários Mínimos\n",
    "- 6: Renda até 8 Salários Mínimos\n",
    "- 7: Renda até 10 Salários Mínimos\n",
    "- 8: Renda até 12 Salários Mínimos\n",
    "- 9: Renda até 15 Salários Mínimos\n",
    "- 10: Renda até 20 Salários Mínimos\n",
    "- 11: Renda maior que 20 Salários Mínimos\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e99ceb0",
   "metadata": {},
   "source": [
    "### Transformações"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6de806d1",
   "metadata": {},
   "source": [
    "Como descrito nas seções acima, as seguintes colunas categóricas serão alteradas\n",
    "\n",
    "0. Drop:\n",
    "    - ``TP_FAIXA_ETARIA``\n",
    "    - ``TP_ENSINO``\n",
    "    - ``CO_MUNICIPIO_ESC``                         \n",
    "    - ``TP_DEPENDENCIA_ADM_ESC``                   \n",
    "    - ``TP_LOCALIZACAO_ESC``                       \n",
    "    - ``TP_SIT_FUNC_ESC``\n",
    "    - ``CO_MUNICIPIO_PROVA`` \n",
    "1. ``TP_ANO_CONCLUIU`` e ``TP_ST_CONCLUSAO`` -> ``TP_CONCLUSAO``\n",
    "    - 1: EM concluído mas sem ano\n",
    "    - 2: EM será concluído em 2023\n",
    "    - 3: EM será concluído após 2023\n",
    "    - 4: EM não cursado\n",
    "    - 5: EM concluído em 2022\n",
    "    - 6: EM concluído entre 2021 e 2018\n",
    "    - 7: EM concluído entre 2017 e 2007\n",
    "    - 8: EM concluído antes de 2007\n",
    "\n",
    "2. ``TP_PRESENCA_CH`` e ``TP_PRESENCA_LC`` -> ``TP_PRESENCA_DIA1``\n",
    "    - 0: Faltou à prova\n",
    "    - 1: Presente na prova\n",
    "    - 2: Eliminado na prova\n",
    "     \n",
    "3. ``TP_PRESENCA_MT`` e ``TP_PRESENCA_CN'`` -> ``TP_PRESENCA_DIA2``\n",
    "    - 0: Faltou à prova\n",
    "    - 1: Presente na prova\n",
    "    - 2: Eliminado na prova\n",
    "\n",
    "4. ``CO_PROVA_LC`` e ``CO_PROVA_CH`` -> ``CO_PROVA_DIA1``\n",
    "    - 1: Prova Comum <- Azul, Amarela, Rosa, Cinza\n",
    "    - 2: Prova Adaptada <- Rosa - Ampliada, Rosa - Superampliada, Laranja - Braile, Laranja - Adaptada Ledor, Verde - Videoprova - Libras\n",
    "    - 3: Reaplicação <- Azul (Reaplicação), Amarela (Reaplicação), Cinza (Reaplicação), Rosa (Reaplicação) ->  (3)\n",
    "    - 4: Ausente <- NaN \n",
    "\n",
    "5. ``CO_PROVA_CN`` e ``CO_PROVA_MT`` -> ``CO_PROVA_DIA2`` \n",
    "    - 1: Prova Comum <- Azul, Amarela, Rosa, Cinza\n",
    "    - 2: Prova Adaptada <- Rosa - Ampliada, Rosa - Superampliada, Laranja - Braile, Laranja - Adaptada Ledor, Verde - Videoprova - Libras\n",
    "    - 3: Reaplicação <- Azul (Reaplicação), Amarela (Reaplicação), Cinza (Reaplicação), Rosa (Reaplicação) ->  (3)\n",
    "    - 4: Ausente <- NaN \n",
    "\n",
    "6. ``Q001`` -> ``ESC_PAI``\n",
    "7. ``Q002`` -> ``ESC_MAE``\n",
    "8. ``Q006`` -> ``RENDA``\n",
    "    - 1: RENDA_NENHUMA <- A\n",
    "    - 2: RENDA_1SM <- B\n",
    "    - 3: RENDA_2SM <- C, D\n",
    "    - 4: RENDA_3SM <- E, F\n",
    "    - 5: RENDA_4SM <- G\n",
    "    - 6: RENDA_6SM <- H, I\n",
    "    - 7: RENDA_10SM <- J, K, L, M\n",
    "    - 8: RENDA_15SM <- N, O\n",
    "    - 9: RENDA_20SM <- P\n",
    "    - 10: RENDA_MAIS <- Q\n",
    "9. ``Q025`` -> ``INTERNET``\n",
    "10. ``TP_STATUS_REDACAO``\n",
    "    - 1: Sem problemas\n",
    "    - 2: Anulada\n",
    "    - 3: Cópia Texto Motivador\n",
    "    - 4: Em Branco\n",
    "    - 6: Fuga ao tema\n",
    "    - 7: Não atendimento ao tipo textual\n",
    "    - 8: Texto insuficiente\n",
    "    - 9: Texto insuficiente\n",
    "    - 10: Ausente <- NaN \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50f934d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exclusoes\n",
    "del df['NU_INSCRICAO']\n",
    "del df['TP_FAIXA_ETARIA']\n",
    "del df['CO_MUNICIPIO_ESC']                         \n",
    "del df['TP_DEPENDENCIA_ADM_ESC']                   \n",
    "del df['TP_LOCALIZACAO_ESC']                       \n",
    "del df['TP_SIT_FUNC_ESC']\n",
    "del df['TP_ENSINO']\n",
    "del df['CO_MUNICIPIO_PROVA']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d0a21a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TP_CONCLUSAO\n",
    "condicoes = [\n",
    "    (df['TP_ANO_CONCLUIU'] == '0') & (df['TP_ST_CONCLUSAO'] == '1'),    # Concluido mas sem ano\n",
    "    (df['TP_ANO_CONCLUIU'] == '0') & (df['TP_ST_CONCLUSAO'] == '2'),    # EM a ser concluido em 2023\n",
    "    (df['TP_ANO_CONCLUIU'] == '0') & (df['TP_ST_CONCLUSAO'] == '3'),    # EM a ser concluido após 2023\n",
    "    (df['TP_ANO_CONCLUIU'] == '0') & (df['TP_ST_CONCLUSAO'] == '4'),    # EM não cursado\n",
    "    (df['TP_ANO_CONCLUIU'] == '1'),                                     # EM concluido em 2022\n",
    "    (df['TP_ANO_CONCLUIU'].isin(['2', '3', '4', '5'])),                 # EM concluido entre 2021 e 2018\n",
    "    (df['TP_ANO_CONCLUIU'].isin(['6', '7', '8', '9', '10', '11',\n",
    "                                    '12', '13', '14', '15', '16'])),    # EM concluido entre 2017 e 2007\n",
    "    (df['TP_ANO_CONCLUIU'] == '17')                                     # EM concluido após 2007\n",
    "]\n",
    "\n",
    "# Valores que serão atribuídos com base nas condições\n",
    "valores = [1, 2, 3, 4, 5, 6, 7, 8]\n",
    "\n",
    "df['TP_CONCLUSAO'] =  np.select(condicoes, valores)\n",
    "df['TP_CONCLUSAO'] = df['TP_CONCLUSAO'].astype('category')\n",
    "\n",
    "df['TP_CONCLUSAO'] = df['TP_CONCLUSAO'].cat.rename_categories({\n",
    "    '1.0': '1',\n",
    "    '2.0': '2',\n",
    "    '3.0': '3',\n",
    "    '4.0': '4',\n",
    "    '6.0': '6',\n",
    "    '7.0': '7',\n",
    "    '8.0': '8'\n",
    "})\n",
    "\n",
    "del df['TP_ANO_CONCLUIU']\n",
    "del df['TP_ST_CONCLUSAO'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bc5345f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TP_PRESENCA_DIA1 e TP_PRESENCA_DIA2\n",
    "df.rename(columns={\n",
    "    'TP_PRESENCA_CH': 'TP_PRESENCA_DIA1',\n",
    "    'TP_PRESENCA_CN': 'TP_PRESENCA_DIA2'\n",
    "}, inplace=True)\n",
    "\n",
    "del df['TP_PRESENCA_LC']\n",
    "del df['TP_PRESENCA_MT']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5039f35",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# CO_PROVA_DIA1\n",
    "condicoes = [\n",
    "    df['CO_PROVA_CH'].isin(['1191.0', '1192.0', '1193.0', '1194.0']),               # Prova Comum\n",
    "    df['CO_PROVA_CH'].isin(['1195.0', '1196.0', '1197.0', '1198.0', '1199.0']),     # Prova Adaptada\n",
    "    df['CO_PROVA_CH'].isin(['1271.0', '1272.0', '1273.0', '1274.0']),               # Prova Reaplicação\n",
    "    df['CO_PROVA_CH'].isna()                                                        # Ausente\n",
    "]\n",
    "\n",
    "\n",
    "\n",
    "# Valores que serão atribuídos com base nas condições\n",
    "valores = [1, 2, 3, 4]\n",
    "\n",
    "df['CO_PROVA_DIA1'] =  np.select(condicoes, valores)\n",
    "df['CO_PROVA_DIA1'] = df['CO_PROVA_DIA1'].astype('category')\n",
    "del df['CO_PROVA_CH']\n",
    "del df['CO_PROVA_LC'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1a46583",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CO_PROVA_DIA2\n",
    "condicoes = [\n",
    "    df['CO_PROVA_CN'].isin(['1221.0', '1222.0', '1223.0', '1224.0']),               # Prova Comum\n",
    "    df['CO_PROVA_CN'].isin(['1225.0', '1226.0', '1227.0', '1228.0', '1229.0']),     # Prova Adaptada\n",
    "    df['CO_PROVA_CN'].isin(['1301.0', '1302.0', '1303.0', '1304.0']),               # Prova Reaplicação\n",
    "    df['CO_PROVA_CN'].isna()                                            # Ausente\n",
    "]\n",
    "\n",
    "# Valores que serão atribuídos com base nas condições\n",
    "valores = [1, 2, 3, 4]\n",
    "\n",
    "df['CO_PROVA_DIA2'] = np.select(condicoes, valores)\n",
    "df['CO_PROVA_DIA2'] = df['CO_PROVA_DIA2'].astype('category')\n",
    "del df['CO_PROVA_CN']\n",
    "del df['CO_PROVA_MT'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2429f482",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ESC_MAE, ESC_PAI, INTERNET\n",
    "df.rename(columns={\n",
    "    'Q001': 'ESC_PAI',\n",
    "    'Q002': 'ESC_MAE',\n",
    "    'Q025': 'INTERNET'\n",
    "}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2b1e9a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# RENDA\n",
    "condicoes = [\n",
    "    df['Q006'] == 'A',\n",
    "    df['Q006'] == 'B',\n",
    "    df['Q006'].isin(['C', 'D']),\n",
    "    df['Q006'].isin(['E', 'F']),\n",
    "    df['Q006'] == 'G',\n",
    "    df['Q006'].isin(['H', 'I']),\n",
    "    df['Q006'].isin(['J', 'K', 'L', 'M']),\n",
    "    df['Q006'].isin(['N', 'O']),\n",
    "    df['Q006'] == 'P',\n",
    "    df['Q006'] == 'Q'\n",
    "]\n",
    "\n",
    "valores = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]\n",
    "\n",
    "df['RENDA'] = np.select(condicoes, valores)\n",
    "df['RENDA'] = df['RENDA'].astype(int).astype('category')\n",
    "\n",
    "del df['Q006']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47400e87",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TP_STATUS_REDACAO\n",
    "\n",
    "condicoes = [\n",
    "    df['TP_STATUS_REDACAO'] == '1.0',\n",
    "    df['TP_STATUS_REDACAO'] == '2.0',\n",
    "    df['TP_STATUS_REDACAO'] == '3.0',\n",
    "    df['TP_STATUS_REDACAO'] == '4.0',\n",
    "    df['TP_STATUS_REDACAO'] == '6.0',\n",
    "    df['TP_STATUS_REDACAO'] == '7.0',\n",
    "    df['TP_STATUS_REDACAO'] == '8.0',\n",
    "    df['TP_STATUS_REDACAO'] == '9.0',\n",
    "    df['TP_STATUS_REDACAO'].isna(),\n",
    "]\n",
    "\n",
    "valores = [1, 2, 3, 4, 6, 7, 8, 9, 10]\n",
    "\n",
    "df['TP_STATUS_REDACAO'] =  np.select(condicoes, valores)\n",
    "df['TP_STATUS_REDACAO'] = df['TP_STATUS_REDACAO'].astype('category')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a8b66ed",
   "metadata": {},
   "source": [
    "## Variáveis Numéricas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16066ba4",
   "metadata": {},
   "source": [
    "#### Dados Notas das Provas por Área de Conhecimento"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c69cb29",
   "metadata": {},
   "source": [
    "Abaixo, segue a análise descritiva da distribuição das notas por área de conhecimento. Foram plotados 5 histogramas, um para cada área de conhecimento. Como o histograma da redação tinha uma distribuição diferente das demais, com valores de notas mais descontinuados e frequências para determinados valores de notas acima dos valores de notas das outras áreas de conhecimento. Por esses motivos, foi decidido plotar as notas de redação separadamente das demais notas.\n",
    "\n",
    "Percebe-se que a mediana está muito próxima da média das notas para todos os histogramas, sugerindo uma distribuição simétrica. Destaca-se a presença de notas zeradas em todas as áreas do conhecimento. Esse comportamento é curioso e será objeto de investigação."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddec5051",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "fig, axes = plt.subplots(2, 2, figsize=(12, 8))\n",
    "colunas = ['NU_NOTA_CN', 'NU_NOTA_CH', 'NU_NOTA_LC', 'NU_NOTA_MT']\n",
    "titulos = ['Nota da prova de Ciências da Natureza',\n",
    "           'Nota da prova de Ciência Humanas',\n",
    "           'Nota da prova de Linguagens e Códigos',\n",
    "           'Nota da prova de Matemática']\n",
    "\n",
    "for ax, col, tit in zip(axes.flatten(), colunas, titulos):\n",
    "    sns.histplot(df[col], bins='auto', ax=ax)\n",
    "\n",
    "    media = df[col].mean()\n",
    "    std = df[col].std()\n",
    "    mediana = df[col].median()\n",
    "\n",
    "    ax.axvline(media, color='red', linestyle='--', linewidth=1.0, label='Média')\n",
    "    ax.axvline(mediana, color='blue', linestyle='--', linewidth=1.0, label='Mediana')\n",
    "    ax.axvline(media + std, color='orange', linestyle='--', linewidth=0.5, label='+1 desvio')\n",
    "    ax.axvline(media - std, color='orange', linestyle='--', linewidth=0.5, label='-1 desvio')\n",
    "    ax.axvline(media + 2*std, color='green', linestyle='--', linewidth=0.5, label='+2 desvios')\n",
    "    ax.axvline(media - 2*std, color='green', linestyle='--', linewidth=0.5, label='-2 desvios')\n",
    "\n",
    "    ax.set_title(f'Histograma \\n{tit}', fontsize=12)\n",
    "    ax.set_xlabel('Nota')\n",
    "    ax.set_ylabel('')\n",
    "    ax.set_xlim(-50, 1000)\n",
    "    ax.set_ylim(0, 8000)\n",
    "\n",
    "    if col == colunas[0]:\n",
    "        ax.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Gráfico da Redação separado\n",
    "col = 'NU_NOTA_REDACAO'\n",
    "media = df[col].mean()\n",
    "std = df[col].std()\n",
    "mediana = df[col].median()\n",
    "\n",
    "plt.figure(figsize=(6, 4))\n",
    "sns.histplot(df[col], bins=50)\n",
    "\n",
    "plt.axvline(media, color='red', linestyle='--', linewidth=1.0, label='Média')\n",
    "plt.axvline(mediana, color='blue', linestyle='--', linewidth=1.0, label='Mediana')\n",
    "plt.axvline(media + std, color='orange', linestyle='--', linewidth=0.5, label='+1 desvio')\n",
    "plt.axvline(media - std, color='orange', linestyle='--', linewidth=0.5, label='-1 desvio')\n",
    "plt.axvline(media + 2*std, color='green', linestyle='--', linewidth=0.5, label='+2 desvios')\n",
    "plt.axvline(media - 2*std, color='green', linestyle='--', linewidth=0.5, label='-2 desvios')\n",
    "\n",
    "plt.title('Histograma \\nNota da prova de redação', fontsize=12)\n",
    "plt.xlabel('Nota')\n",
    "plt.ylabel('')\n",
    "plt.xlim(-50, 1000)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5646c175",
   "metadata": {},
   "source": [
    "#### Dados Notas da Redação por Competência"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "820c3a19",
   "metadata": {},
   "source": [
    "Abaixo, segue a análise descritiva da distribuição das notas por competência na prova de redação. Foram plotados 5 histogramas, um para cada competência.\n",
    "\n",
    "Percebe-se que a mediana está muito próxima da média, sugerindo uma distribuição simétrica. Destaca-se a presença de notas zeradas em todas as competências, como foi observado também para as notas das provas por área de conhecimento acima. Esse comportamento é curioso e será objeto de investigação também."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f462eb8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(3, 2, figsize=(12, 12))\n",
    "colunas = ['NU_NOTA_COMP1', 'NU_NOTA_COMP2', 'NU_NOTA_COMP3', 'NU_NOTA_COMP4', 'NU_NOTA_COMP5']\n",
    "titulos = ['Nota Competência 1 - Redação',\n",
    "           'Nota Competência 2 - Redação',\n",
    "           'Nota Competência 3 - Redação',\n",
    "           'Nota Competência 4 - Redação',\n",
    "           'Nota Competência 5 - Redação']\n",
    "\n",
    "for ax, col, tit in zip(axes.flatten(), colunas, titulos):\n",
    "    sns.histplot(df[col], bins=10, ax=ax)\n",
    "\n",
    "    media = df[col].mean()\n",
    "    std = df[col].std()\n",
    "    mediana = df[col].median()\n",
    "\n",
    "    ax.axvline(media, color='red', linestyle='--', linewidth=1.0, label='Média')\n",
    "    ax.axvline(mediana, color='blue', linestyle='--', linewidth=1.0, label='Mediana')\n",
    "    ax.axvline(media + std, color='orange', linestyle='--', linewidth=0.5, label='+1 desvio')\n",
    "    ax.axvline(media - std, color='orange', linestyle='--', linewidth=0.5, label='-1 desvio')\n",
    "    ax.axvline(media + 2*std, color='green', linestyle='--', linewidth=0.5, label='+2 desvios')\n",
    "    ax.axvline(media - 2*std, color='green', linestyle='--', linewidth=0.5, label='-2 desvios')\n",
    "\n",
    "    ax.set_title(f'Histograma \\n{tit}', fontsize=12)\n",
    "    ax.set_xlabel('Nota')\n",
    "    ax.set_ylabel('')\n",
    "    ax.set_xlim(0, 200) \n",
    "    ax.set_ylim(0, 250000)\n",
    "  \n",
    "    if col == colunas[0]:\n",
    "        ax.legend()\n",
    "\n",
    "# Remove o sexto subplot vazio (última célula da grade 2x3)\n",
    "if len(colunas) < len(axes.flatten()):\n",
    "    for ax in axes.flatten()[len(colunas):]:\n",
    "        fig.delaxes(ax)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84d688e9",
   "metadata": {},
   "source": [
    "### Transformação"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02960dd9",
   "metadata": {},
   "source": [
    "Com intuito de categorizar as variáveis numéricas notas (área de conhecimento e competencia da prova de redação) foram adotadas 5 faixas: ausente, zerou, baixa, media e alta. O critério de classificação das notas em cada uma das faixas foi:  \n",
    "\n",
    "**ausente:** valores NA do banco, que significa pessoas que não compareceram ou tiveram sua prova anulada no dia da prova da respectiva área de conhecimento.  \n",
    "**zero:** valor da nota igual a 0 (zero).  \n",
    "**baixa:** valor da nota inferior a media - 1 desvios-padrão.  \n",
    "**media:** valor da nota entre a media - 1 desvios-padrão e media + 1 desvios-padrão.  \n",
    "**alta:** valor da nota entre a media + 1 desvios-padrão e a media + 2 desvios-padrão.  \n",
    "**super:** valor da nota superior a media + 2 desvios-padrão.  \n",
    "\n",
    "Excepcionalmente, para as variáveis notas das competências da prova de redação (``NU_NOTA_COMP1``, ``NU_NOTA_COMP2``, ``NU_NOTA_COMP3``, ``NU_NOTA_COMP4``, ``NU_NOTA_COMP5``) foi utilizado critério diferente para classificar a nota na faixa muito alta, que consiste em notas iguais a 200. Similarmente, para a nota da redação ``NU_NOTA_REDACAO`` foi classificado como nota muito alta aquelas superiores a 900. Tal decisão foi tomada, pois como pode ser verificado no histograma **Nota da prova de redação** e **Nota Compentência da redação**, não existem dados acima de 2 desvios-padrão.  \n",
    "\n",
    "Com a transformação dos dados numéricos, a codificação das colunas ``NU_NOTA_CN``, ``NU_NOTA_CH``, ``NU_NOTA_LC``, ``NU_NOTA_MT``, ``NU_NOTA_REDACAO``, ``NU_NOTA_COMP1``, ``NU_NOTA_COMP2``, ``NU_NOTA_COMP3``, ``NU_NOTA_COMP4``, ``NU_NOTA_COMP5`` foi:  \n",
    "\n",
    "- 0: Faltou à prova  \n",
    "- 1: zero  \n",
    "- 2: baixa  \n",
    "- 3: media  \n",
    "- 4: alta  \n",
    "- 5: super  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7db30e31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transformacao das variaveis numericas em categoricas, segunda as faixas estipuladas\n",
    "\n",
    "colunas = ['NU_NOTA_CN', 'NU_NOTA_CH', 'NU_NOTA_LC', 'NU_NOTA_MT',  'NU_NOTA_REDACAO',\n",
    "           'NU_NOTA_COMP1', 'NU_NOTA_COMP2', 'NU_NOTA_COMP3', 'NU_NOTA_COMP4', 'NU_NOTA_COMP5']\n",
    "\n",
    "for col in colunas:\n",
    "    media = df[col].mean()\n",
    "    std = df[col].std()\n",
    "\n",
    "    if col not in ['NU_NOTA_REDACAO', 'NU_NOTA_COMP1', 'NU_NOTA_COMP2', 'NU_NOTA_COMP3', 'NU_NOTA_COMP4', 'NU_NOTA_COMP5']:\n",
    "        condicoes = [\n",
    "            df[col].isna(),\n",
    "            df[col] == 0,\n",
    "            df[col] < media - std,\n",
    "            df[col] <= media + std,\n",
    "            df[col] <= media + 2*std,\n",
    "            df[col] > media + 2*std\n",
    "        ]\n",
    "    elif col == 'NU_NOTA_REDACAO': \n",
    "        condicoes = [\n",
    "            df[col].isna(),\n",
    "            df[col] == 0,\n",
    "            df[col] < media - std,\n",
    "            df[col] <= media + std,\n",
    "            (df[col] > media + std) & (df[col] < 900),\n",
    "            df[col] >= 900\n",
    "        ]\n",
    "    else:\n",
    "        condicoes = [\n",
    "            df[col].isna(),\n",
    "            df[col] == 0,\n",
    "            df[col] < media - std,\n",
    "            df[col] <= media + std,\n",
    "            (df[col] > media + std) & (df[col] < 200),\n",
    "            df[col] == 200\n",
    "        ]\n",
    "\n",
    "    valores = [0, 1, 2, 3, 4, 5]\n",
    "\n",
    "    df[col] =  np.select(condicoes, valores)\n",
    "    df[col] = df[col].astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e245662",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Proporcao das faixas das notas\n",
    "\n",
    "print(\"\\n:\")\n",
    "\n",
    "colunas = ['NU_NOTA_CN', 'NU_NOTA_CH', 'NU_NOTA_LC', 'NU_NOTA_MT', 'NU_NOTA_REDACAO',\n",
    "           'NU_NOTA_COMP1', 'NU_NOTA_COMP2', 'NU_NOTA_COMP3', 'NU_NOTA_COMP4', 'NU_NOTA_COMP5']\n",
    "contagens = {}\n",
    "percentual = {}\n",
    "\n",
    "for col in colunas:\n",
    "    \n",
    "    contagens[f'tp_{col}'] = df[col].value_counts(dropna=False)\n",
    "    percentual[f'tp_{col}_pct'] = df[col].value_counts(normalize=True, dropna=False) * 100\n",
    "\n",
    "    resultado = pd.DataFrame({\n",
    "        'Frequência': contagens[f'tp_{col}'],\n",
    "        'Percentual (%)': percentual[f'tp_{col}_pct'].round(2)\n",
    "    })\n",
    "    \n",
    "    print(resultado, '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfd0fd98",
   "metadata": {},
   "source": [
    "## Conferência das transformações"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a2ae6c8",
   "metadata": {},
   "source": [
    "No intuito de conferir se as transformações do banco de dados foram feitoas corretamente, ou seja, para todas as variáveis selecionadas no dataframe, precisam estar como categóricas e rotuladas com números."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5bd0b4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in df.select_dtypes(include='category').columns:\n",
    "    valores = df[col].unique().tolist()\n",
    "    try:\n",
    "        # Tenta converter para número e ordenar\n",
    "        valores_ordenados = sorted(valores, key=lambda x: float(x))\n",
    "    except ValueError:\n",
    "        # Se não forem numéricos, mantém a ordem original\n",
    "        valores_ordenados = valores\n",
    "    print(f'\\n{col}: {valores_ordenados}')\n",
    "\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c846384b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transforma dataframe em formato transacional\n",
    "\n",
    "df_binario = pd.get_dummies(df, prefix_sep='_', dtype=bool)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b8c3828",
   "metadata": {},
   "outputs": [],
   "source": [
    "# nomes_colunas = df_binario.columns.tolist()\n",
    "# print(nomes_colunas)\n",
    "\n",
    "# cria dicionario com os nomes das colunas\n",
    "\n",
    "dic_enem = {\n",
    "    'TP_SEXO_F': 'Feminino',\n",
    "    'TP_SEXO_M': 'Masculino',\n",
    "    'TP_ESTADO_CIVIL_0': 'Não informado',\n",
    "    'TP_ESTADO_CIVIL_1': 'Solteiro(a)',\n",
    "    'TP_ESTADO_CIVIL_2': 'Casado(a)/União estável',\n",
    "    'TP_ESTADO_CIVIL_3': 'Divorciado(a)/Separado(a)',\n",
    "    'TP_ESTADO_CIVIL_4': 'Viúvo(a)',\n",
    "    'TP_COR_RACA_0': 'Não declarado',\n",
    "    'TP_COR_RACA_1': 'Branca',\n",
    "    'TP_COR_RACA_2': 'Preta',\n",
    "    'TP_COR_RACA_3': 'Parda',\n",
    "    'TP_COR_RACA_4': 'Amarela',\n",
    "    'TP_COR_RACA_5': 'Indígena',\n",
    "    'TP_NACIONALIDADE_0': 'Não informado',\n",
    "    'TP_NACIONALIDADE_1': 'Brasileiro(a)',\n",
    "    'TP_NACIONALIDADE_2': 'Naturalizado',\n",
    "    'TP_NACIONALIDADE_3': 'Estrangeiro(a)',\n",
    "    'TP_NACIONALIDADE_4': 'Brasileiro nascido no exterior',\n",
    "    'TP_ESCOLA_1': 'Não Respondeu',\n",
    "    'TP_ESCOLA_2': 'Pública',\n",
    "    'TP_ESCOLA_3': 'Privada',\n",
    "    'IN_TREINEIRO_0': 'Não',\n",
    "    'IN_TREINEIRO_1': 'Sim',\n",
    "    'TP_PRESENCA_DIA2_0': 'Faltou à prova',\n",
    "    'TP_PRESENCA_DIA2_1': 'Presente na prova',\n",
    "    'TP_PRESENCA_DIA2_2': 'Eliminado na prova',\n",
    "    'TP_PRESENCA_DIA1_0': 'Faltou à prova',\n",
    "    'TP_PRESENCA_DIA1_1': 'Presente na prova',\n",
    "    'TP_PRESENCA_DIA1_2': 'Eliminado na prova',\n",
    "    'NU_NOTA_CN_0': 'Faltou à prova',\n",
    "    'NU_NOTA_CN_1': 'zero',\n",
    "    'NU_NOTA_CN_2': 'baixa',\n",
    "    'NU_NOTA_CN_3': 'media',\n",
    "    'NU_NOTA_CN_4': 'alta',\n",
    "    'NU_NOTA_CN_5': 'super',\n",
    "    'NU_NOTA_CH_0': 'Faltou à prova',\n",
    "    'NU_NOTA_CH_1': 'zero',\n",
    "    'NU_NOTA_CH_2': 'baixa',\n",
    "    'NU_NOTA_CH_3': 'media',\n",
    "    'NU_NOTA_CH_4': 'alta',\n",
    "    'NU_NOTA_CH_5': 'super',\n",
    "    'NU_NOTA_LC_0': 'Faltou à prova',\n",
    "    'NU_NOTA_LC_1': 'zero',\n",
    "    'NU_NOTA_LC_2': 'baixa',\n",
    "    'NU_NOTA_LC_3': 'media',\n",
    "    'NU_NOTA_LC_4': 'alta',\n",
    "    'NU_NOTA_LC_5': 'super',\n",
    "    'NU_NOTA_MT_0': 'Faltou à prova',\n",
    "    'NU_NOTA_MT_1': 'zero',\n",
    "    'NU_NOTA_MT_2': 'baixa',\n",
    "    'NU_NOTA_MT_3': 'media',\n",
    "    'NU_NOTA_MT_4': 'alta',\n",
    "    'NU_NOTA_MT_5': 'super',\n",
    "    'TP_LINGUA_0': 'Inglês',\n",
    "    'TP_LINGUA_1': 'Espanhol',\n",
    "    'TP_STATUS_REDACAO_1': 'Sem problemas',\n",
    "    'TP_STATUS_REDACAO_2': 'Anulada',\n",
    "    'TP_STATUS_REDACAO_3': 'Cópia Texto Motivador',\n",
    "    'TP_STATUS_REDACAO_4': 'Em Branco',\n",
    "    'TP_STATUS_REDACAO_6': 'Fuga ao tema',\n",
    "    'TP_STATUS_REDACAO_7': 'Não atendimento ao tipo textual',\n",
    "    'TP_STATUS_REDACAO_8': 'Texto insuficiente',\n",
    "    'TP_STATUS_REDACAO_9': 'Texto insuficiente',\n",
    "    'TP_STATUS_REDACAO_10': 'Ausente',\n",
    "    'NU_NOTA_COMP1_0': 'Faltou à prova',\n",
    "    'NU_NOTA_COMP1_1': 'zero',\n",
    "    'NU_NOTA_COMP1_2': 'baixa',\n",
    "    'NU_NOTA_COMP1_3': 'media',\n",
    "    'NU_NOTA_COMP1_4': 'alta',\n",
    "    'NU_NOTA_COMP1_5': 'super',\n",
    "    'NU_NOTA_COMP2_0': 'Faltou à prova',\n",
    "    'NU_NOTA_COMP2_1': 'zero',\n",
    "    'NU_NOTA_COMP2_2': 'baixa',\n",
    "    'NU_NOTA_COMP2_3': 'media',\n",
    "    'NU_NOTA_COMP2_4': 'alta',\n",
    "    'NU_NOTA_COMP2_5': 'super',\n",
    "    'NU_NOTA_COMP3_0': 'Faltou à prova',\n",
    "    'NU_NOTA_COMP3_1': 'zero',\n",
    "    'NU_NOTA_COMP3_2': 'baixa',\n",
    "    'NU_NOTA_COMP3_3': 'media',\n",
    "    'NU_NOTA_COMP3_4': 'alta',\n",
    "    'NU_NOTA_COMP3_5': 'super',\n",
    "    'NU_NOTA_COMP4_0': 'Faltou à prova',\n",
    "    'NU_NOTA_COMP4_1': 'zero',\n",
    "    'NU_NOTA_COMP4_2': 'baixa',\n",
    "    'NU_NOTA_COMP4_3': 'media',\n",
    "    'NU_NOTA_COMP4_4': 'alta',\n",
    "    'NU_NOTA_COMP4_5': 'super',\n",
    "    'NU_NOTA_COMP5_0': 'Faltou à prova',\n",
    "    'NU_NOTA_COMP5_1': 'zero',\n",
    "    'NU_NOTA_COMP5_2': 'baixa',\n",
    "    'NU_NOTA_COMP5_3': 'media',\n",
    "    'NU_NOTA_COMP5_4': 'alta',\n",
    "    'NU_NOTA_COMP5_5': 'super',\n",
    "    'NU_NOTA_REDACAO_0': 'Faltou à prova',\n",
    "    'NU_NOTA_REDACAO_1': 'zero',\n",
    "    'NU_NOTA_REDACAO_2': 'baixa',\n",
    "    'NU_NOTA_REDACAO_3': 'media',\n",
    "    'NU_NOTA_REDACAO_4': 'alta',\n",
    "    'NU_NOTA_REDACAO_5': 'super',\n",
    "    'ESC_PAI_A': 'Nunca estudou',\n",
    "    'ESC_PAI_B': 'Não completou a 4ª série / 5º ano do Ensino Fundamental',\n",
    "    'ESC_PAI_C': 'Completou a 4ª série / 5º ano',\n",
    "    'ESC_PAI_D': 'Completou o Ensino Fundamental',\n",
    "    'ESC_PAI_E': 'Completou o Ensino Médio',\n",
    "    'ESC_PAI_F': 'Completou a graduação',\n",
    "    'ESC_PAI_G': 'Completou a pós-graduação',\n",
    "    'ESC_PAI_H': 'Não sei',\n",
    "    'ESC_MAE_A': 'Nunca estudou',\n",
    "    'ESC_MAE_B': 'Não completou a 4ª série / 5º ano do Ensino Fundamental',\n",
    "    'ESC_MAE_C': 'Completou a 4ª série / 5º ano',\n",
    "    'ESC_MAE_D': 'Completou o Ensino Fundamental',\n",
    "    'ESC_MAE_E': 'Completou o Ensino Médio',\n",
    "    'ESC_MAE_F': 'Completou a graduação',\n",
    "    'ESC_MAE_G': 'Completou a pós-graduação',\n",
    "    'ESC_MAE_H': 'Não sei',\n",
    "    'INTERNET_A': 'Não tem acesso à Internet',\n",
    "    'INTERNET_B': 'Tem acesso à Internet',\n",
    "    'TP_CONCLUSAO_1': 'Já concluiu o Ensino Médio',\n",
    "    'TP_CONCLUSAO_2': 'Concluiu em anos anteriores',\n",
    "    'TP_CONCLUSAO_3': 'Concluiu no ano do exame',\n",
    "    'TP_CONCLUSAO_4': 'Está cursando e concluirá no ano do exame',\n",
    "    'TP_CONCLUSAO_5': 'Está cursando e concluirá após o ano do exame',\n",
    "    'TP_CONCLUSAO_6': 'Não concluiu e não está cursando',\n",
    "    'TP_CONCLUSAO_7': 'Não respondeu',\n",
    "    'TP_CONCLUSAO_8': 'Participante com deficiência auditiva e surdez',\n",
    "    'CO_PROVA_DIA1_1': 'Linguagens',\n",
    "    'CO_PROVA_DIA1_2': 'Ciências Humanas e suas Tecnologias',\n",
    "    'CO_PROVA_DIA1_3': 'Linguagens + Ciências Humanas',\n",
    "    'CO_PROVA_DIA1_4': 'Redação + Linguagens + Ciências Humanas',\n",
    "    'CO_PROVA_DIA2_1': 'Matemática e suas Tecnologias',\n",
    "    'CO_PROVA_DIA2_2': 'Ciências da Natureza e suas Tecnologias',\n",
    "    'CO_PROVA_DIA2_3': 'Matemática + Ciências da Natureza',\n",
    "    'CO_PROVA_DIA2_4': 'Todas as provas do segundo dia',\n",
    "    'RENDA_1': 'Nenhuma renda',\n",
    "    'RENDA_2': 'RENDA_1SM',\n",
    "    'RENDA_3': 'RENDA_2SM',\n",
    "    'RENDA_4': 'RENDA_3SM',\n",
    "    'RENDA_5': 'RENDA_4SM',\n",
    "    'RENDA_6': 'RENDA_6SM',\n",
    "    'RENDA_7': 'RENDA_10SM',\n",
    "    'RENDA_8': 'RENDA_15SM',\n",
    "    'RENDA_9': 'RENDA_20SM',\n",
    "    'RENDA_10': 'RENDA_MAIS',\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "447660f6",
   "metadata": {},
   "source": [
    "## Notas sobre o uso da LLM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb80eaaa",
   "metadata": {},
   "source": [
    "- A LLM foi usada para executar construir o código da amostragem otimizada em memória do arquivo de microdados do ENEM. O algoritmo gerado para selecionar e amostrar os dados foi bastante satisfatório, a não ser por um pequeno erro lógico no final: na fase ``# junta tudo``, o código tenta tirar novamente 800_000 amostras de uma lista que já tem (teoricamente) 800_000 amostras, então essa amostragem não faz sentido. Na prática, ainda, o código provavelmente vai gerar um erro, já que nosso banco não tem exatamente 4M registros e o resultado terá um pouco menos que 800k amostras.\n",
    "- No momento da análise exploratória de dados, foi muito satisfatória ao sugerir gráficos que seriam mais adequados aos dados, mas o código gerado trazia muitos detalhes no gráfico que dificultavam a visualização dos dados. Por isso, foi preciso fazer uma limpeza após o código gerado.\n",
    "- Para gerar dicionários das variáveis categóricas, a LLM foi extremamente útil, pois poupou um trabalho manual que demandaria tempo.\n",
    "\n",
    "Na análise das variáveis numéricas a LLM apresentou um desempenho satisfatório. Foi capaz de construir histogramas adequados, distribuindo de forma coerente os valores das notas das provas em faixas representativas. No entanto, a definição das faixas com base na quantidade de desvios-padrão, bem como a criação das categorias específicas para notas ausentes e notas zeradas foram decisões tomadas pelo analista.\n",
    "\n",
    "Embora o código de geração de histogramas sugerido pela LLM tenha servido como base, aspectos mais específicos — como a definição dos limites dos eixos x e y e a separação da nota de redação em um gráfico distinto — não puderam ser antecipados, uma vez que a LLM não possuía acesso aos dados. Sua sugestão de elaborar o histograma foi fornecida de forma genérica e, portanto, tais ajustes também foram realizados pelo analista.\n",
    "\n",
    "Em especial, a LLM foi extremamente útil para um DOS integrante da dupla que não é usuário da linguagem Python. Então toda a intalação e adequação do ambiente (env, requirements.txt, Jupyter) e construção do código foram feitas com a ajuda da LLM.\n",
    "\n",
    "https://chatgpt.com/share/6812da0f-2b38-8013-abc6-01dc19621ab7\n",
    "\n",
    "https://chatgpt.com/share/68154c77-01d8-8005-9bbb-37c25889c447"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
