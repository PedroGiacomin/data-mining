{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f5337151",
   "metadata": {},
   "source": [
    "# Modelagem"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a1c9e74",
   "metadata": {},
   "source": [
    "## Tratamento (condensado)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b3ca462",
   "metadata": {},
   "source": [
    "Aqui é feito o tratamento completo, que foi melhor explicado em \"treatment.ipynb\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4cc8d4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "\n",
    "# Configurações\n",
    "DATA_PATH = Path().resolve() / 'data'\n",
    "ARQUIVO_AMOSTRA_PATH = DATA_PATH / 'raw' / 'microdados_enem_2023_sample.csv'\n",
    "\n",
    "# Definição dos tipos\n",
    "colunas_float = [\n",
    "    'NU_NOTA_CN', 'NU_NOTA_CH', 'NU_NOTA_LC', 'NU_NOTA_MT',\n",
    "    'NU_NOTA_COMP1', 'NU_NOTA_COMP2', 'NU_NOTA_COMP3', 'NU_NOTA_COMP4',\n",
    "    'NU_NOTA_COMP5', 'NU_NOTA_REDACAO'\n",
    "]\n",
    "\n",
    "colunas_string = [\n",
    "    'NU_INSCRICAO', 'CO_MUNICIPIO_ESC', 'CO_MUNICIPIO_PROVA'\n",
    "]\n",
    "\n",
    "# Captura os nomes das colunas\n",
    "colunas = pd.read_csv(ARQUIVO_AMOSTRA_PATH, nrows=0, encoding='latin1').columns.tolist()\n",
    "\n",
    "# Preparar o dicionário de tipos\n",
    "dtypes = {}\n",
    "for col in colunas:\n",
    "    if col in colunas_float:\n",
    "        dtypes[col] = 'float32'\n",
    "    elif col in colunas_string:\n",
    "        dtypes[col] = 'string'\n",
    "    else:\n",
    "        dtypes[col] = 'category'\n",
    "\n",
    "# Leitura com tipos otimizados\n",
    "df = pd.read_csv(ARQUIVO_AMOSTRA_PATH, dtype=dtypes, encoding='latin1')\n",
    "\n",
    "# Define regioes\n",
    "# REGIAO\n",
    "df['REGIAO'] = df['CO_MUNICIPIO_PROVA'].apply(lambda x: x[0])\n",
    "df['REGIAO'] = df['REGIAO'].astype('category')\n",
    "df['REGIAO'].value_counts(normalize=True, dropna=False)\n",
    "\n",
    "# Exclusoes\n",
    "del df['NU_INSCRICAO']\n",
    "del df['TP_FAIXA_ETARIA']\n",
    "del df['CO_MUNICIPIO_ESC']                         \n",
    "del df['TP_DEPENDENCIA_ADM_ESC']                   \n",
    "del df['TP_LOCALIZACAO_ESC']                       \n",
    "del df['TP_SIT_FUNC_ESC']\n",
    "del df['TP_ENSINO']\n",
    "del df['CO_MUNICIPIO_PROVA']\n",
    "\n",
    "# TP_CONCLUSAO\n",
    "condicoes = [\n",
    "    (df['TP_ANO_CONCLUIU'] == '0') & (df['TP_ST_CONCLUSAO'] == '1'),    # Concluido mas sem ano\n",
    "    (df['TP_ANO_CONCLUIU'] == '0') & (df['TP_ST_CONCLUSAO'] == '2'),    # EM a ser concluido em 2023\n",
    "    (df['TP_ANO_CONCLUIU'] == '0') & (df['TP_ST_CONCLUSAO'] == '3'),    # EM a ser concluido após 2023\n",
    "    (df['TP_ANO_CONCLUIU'] == '0') & (df['TP_ST_CONCLUSAO'] == '4'),    # EM não cursado\n",
    "    (df['TP_ANO_CONCLUIU'] == '1'),                                     # EM concluido em 2022\n",
    "    (df['TP_ANO_CONCLUIU'].isin(['2', '3', '4', '5'])),                 # EM concluido entre 2021 e 2018\n",
    "    (df['TP_ANO_CONCLUIU'].isin(['6', '7', '8', '9', '10', '11',\n",
    "                                    '12', '13', '14', '15', '16'])),    # EM concluido entre 2017 e 2007\n",
    "    (df['TP_ANO_CONCLUIU'] == '17')                                     # EM concluido após 2007\n",
    "]\n",
    "\n",
    "# Valores que serão atribuídos com base nas condições\n",
    "valores = [1, 2, 3, 4, 5, 6, 7, 8]\n",
    "\n",
    "df['TP_CONCLUSAO'] =  np.select(condicoes, valores)\n",
    "df['TP_CONCLUSAO'] = df['TP_CONCLUSAO'].astype('category')\n",
    "\n",
    "df['TP_CONCLUSAO'] = df['TP_CONCLUSAO'].cat.rename_categories({\n",
    "    '1.0': '1',\n",
    "    '2.0': '2',\n",
    "    '3.0': '3',\n",
    "    '4.0': '4',\n",
    "    '6.0': '6',\n",
    "    '7.0': '7',\n",
    "    '8.0': '8'\n",
    "})\n",
    "\n",
    "del df['TP_ANO_CONCLUIU']\n",
    "del df['TP_ST_CONCLUSAO'] \n",
    "\n",
    "# TP_PRESENCA_DIA1 e TP_PRESENCA_DIA2\n",
    "df.rename(columns={\n",
    "    'TP_PRESENCA_CH': 'TP_PRESENCA_DIA1',\n",
    "    'TP_PRESENCA_CN': 'TP_PRESENCA_DIA2'\n",
    "}, inplace=True)\n",
    "\n",
    "del df['TP_PRESENCA_LC']\n",
    "del df['TP_PRESENCA_MT']\n",
    "\n",
    "# CO_PROVA_DIA1\n",
    "condicoes = [\n",
    "    df['CO_PROVA_CH'].isin(['1191.0', '1192.0', '1193.0', '1194.0']),               # Prova Comum\n",
    "    df['CO_PROVA_CH'].isin(['1195.0', '1196.0', '1197.0', '1198.0', '1199.0']),     # Prova Adaptada\n",
    "    df['CO_PROVA_CH'].isin(['1271.0', '1272.0', '1273.0', '1274.0']),               # Prova Reaplicação\n",
    "    df['CO_PROVA_CH'].isna()                                                        # Ausente\n",
    "]\n",
    "\n",
    "# Valores que serão atribuídos com base nas condições\n",
    "valores = [1, 2, 3, 4]\n",
    "\n",
    "df['CO_PROVA_DIA1'] =  np.select(condicoes, valores)\n",
    "df['CO_PROVA_DIA1'] = df['CO_PROVA_DIA1'].astype('category')\n",
    "del df['CO_PROVA_CH']\n",
    "del df['CO_PROVA_LC'] \n",
    "\n",
    "# CO_PROVA_DIA2\n",
    "condicoes = [\n",
    "    df['CO_PROVA_CN'].isin(['1221.0', '1222.0', '1223.0', '1224.0']),               # Prova Comum\n",
    "    df['CO_PROVA_CN'].isin(['1225.0', '1226.0', '1227.0', '1228.0', '1229.0']),     # Prova Adaptada\n",
    "    df['CO_PROVA_CN'].isin(['1301.0', '1302.0', '1303.0', '1304.0']),               # Prova Reaplicação\n",
    "    df['CO_PROVA_CN'].isna()                                            # Ausente\n",
    "]\n",
    "\n",
    "# Valores que serão atribuídos com base nas condições\n",
    "valores = [1, 2, 3, 4]\n",
    "\n",
    "df['CO_PROVA_DIA2'] = np.select(condicoes, valores)\n",
    "df['CO_PROVA_DIA2'] = df['CO_PROVA_DIA2'].astype('category')\n",
    "del df['CO_PROVA_CN']\n",
    "del df['CO_PROVA_MT'] \n",
    "\n",
    "# ESC_MAE, ESC_PAI, INTERNET\n",
    "df.rename(columns={\n",
    "    'Q001': 'ESC_PAI',\n",
    "    'Q002': 'ESC_MAE',\n",
    "    'Q025': 'INTERNET'\n",
    "}, inplace=True)\n",
    "\n",
    "# RENDA\n",
    "condicoes = [\n",
    "    df['Q006'] == 'A',\n",
    "    df['Q006'] == 'B',\n",
    "    df['Q006'].isin(['C', 'D']),\n",
    "    df['Q006'].isin(['E', 'F']),\n",
    "    df['Q006'] == 'G',\n",
    "    df['Q006'].isin(['H', 'I']),\n",
    "    df['Q006'].isin(['J', 'K', 'L', 'M']),\n",
    "    df['Q006'].isin(['N', 'O']),\n",
    "    df['Q006'] == 'P',\n",
    "    df['Q006'] == 'Q'\n",
    "]\n",
    "\n",
    "valores = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]\n",
    "\n",
    "df['RENDA'] = np.select(condicoes, valores)\n",
    "df['RENDA'] = df['RENDA'].astype(int).astype('category')\n",
    "\n",
    "del df['Q006']\n",
    "\n",
    "# TP_STATUS_REDACAO\n",
    "\n",
    "condicoes = [\n",
    "    df['TP_STATUS_REDACAO'] == '1.0',\n",
    "    df['TP_STATUS_REDACAO'] == '2.0',\n",
    "    df['TP_STATUS_REDACAO'] == '3.0',\n",
    "    df['TP_STATUS_REDACAO'] == '4.0',\n",
    "    df['TP_STATUS_REDACAO'] == '6.0',\n",
    "    df['TP_STATUS_REDACAO'] == '7.0',\n",
    "    df['TP_STATUS_REDACAO'] == '8.0',\n",
    "    df['TP_STATUS_REDACAO'] == '9.0',\n",
    "    df['TP_STATUS_REDACAO'].isna(),\n",
    "]\n",
    "\n",
    "valores = [1, 2, 3, 4, 6, 7, 8, 9, 10]\n",
    "\n",
    "df['TP_STATUS_REDACAO'] =  np.select(condicoes, valores)\n",
    "df['TP_STATUS_REDACAO'] = df['TP_STATUS_REDACAO'].astype('category')\n",
    "\n",
    "\n",
    "# Transformacao das variaveis numericas em categoricas, segunda as faixas estipuladas\n",
    "colunas = ['NU_NOTA_CN', 'NU_NOTA_CH', 'NU_NOTA_LC', 'NU_NOTA_MT',  'NU_NOTA_REDACAO',\n",
    "           'NU_NOTA_COMP1', 'NU_NOTA_COMP2', 'NU_NOTA_COMP3', 'NU_NOTA_COMP4', 'NU_NOTA_COMP5']\n",
    "\n",
    "for col in colunas:\n",
    "    media = df[col].mean()\n",
    "    std = df[col].std()\n",
    "\n",
    "    if col not in ['NU_NOTA_REDACAO', 'NU_NOTA_COMP1', 'NU_NOTA_COMP2', 'NU_NOTA_COMP3', 'NU_NOTA_COMP4', 'NU_NOTA_COMP5']:\n",
    "        condicoes = [\n",
    "            df[col].isna(),\n",
    "            df[col] == 0,\n",
    "            df[col] < media - std,\n",
    "            df[col] <= media + std,\n",
    "            df[col] <= media + 2*std,\n",
    "            df[col] > media + 2*std\n",
    "        ]\n",
    "    elif col == 'NU_NOTA_REDACAO': \n",
    "        condicoes = [\n",
    "            df[col].isna(),\n",
    "            df[col] == 0,\n",
    "            df[col] < media - std,\n",
    "            df[col] <= media + std,\n",
    "            (df[col] > media + std) & (df[col] < 900),\n",
    "            df[col] >= 900\n",
    "        ]\n",
    "    else:\n",
    "        condicoes = [\n",
    "            df[col].isna(),\n",
    "            df[col] == 0,\n",
    "            df[col] < media - std,\n",
    "            df[col] <= media + std,\n",
    "            (df[col] > media + std) & (df[col] < 200),\n",
    "            df[col] == 200\n",
    "        ]\n",
    "\n",
    "    valores = [0, 1, 2, 3, 4, 5]\n",
    "\n",
    "    df[col] =  np.select(condicoes, valores)\n",
    "    df[col] = df[col].astype('category')\n",
    "\n",
    "# Proporcao das faixas das notas\n",
    "print(\"\\n:\")\n",
    "\n",
    "colunas = ['NU_NOTA_CN', 'NU_NOTA_CH', 'NU_NOTA_LC', 'NU_NOTA_MT', 'NU_NOTA_REDACAO',\n",
    "           'NU_NOTA_COMP1', 'NU_NOTA_COMP2', 'NU_NOTA_COMP3', 'NU_NOTA_COMP4', 'NU_NOTA_COMP5']\n",
    "contagens = {}\n",
    "percentual = {}\n",
    "\n",
    "for col in colunas:\n",
    "    \n",
    "    contagens[f'tp_{col}'] = df[col].value_counts(dropna=False)\n",
    "    percentual[f'tp_{col}_pct'] = df[col].value_counts(normalize=True, dropna=False) * 100\n",
    "\n",
    "    resultado = pd.DataFrame({\n",
    "        'Frequência': contagens[f'tp_{col}'],\n",
    "        'Percentual (%)': percentual[f'tp_{col}_pct'].round(2)\n",
    "    })\n",
    "    \n",
    "    print(resultado, '\\n')\n",
    "\n",
    "# # Informações para conferência\n",
    "# print(\"=\"*40)\n",
    "# print(f\"Memória usada: {df.memory_usage(deep=True).sum() / (1024 ** 2):.2f} MB\")\n",
    "# print(f\"Quantidade de colunas: {df.shape[1]}\")\n",
    "# print(f\"Quantidade de linhas: {df.shape[0]}\")\n",
    "# print(\"=\"*40)\n",
    "\n",
    "# # Tipos de dados\n",
    "# print(\"\\nTipos de dados por coluna:\")\n",
    "# print(df.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f48dc53a",
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in df.select_dtypes(include='category').columns:\n",
    "    valores = df[col].unique().tolist()\n",
    "    try:\n",
    "        # Tenta converter para número e ordenar\n",
    "        valores_ordenados = sorted(valores, key=lambda x: float(x))\n",
    "    except ValueError:\n",
    "        # Se não forem numéricos, mantém a ordem original\n",
    "        valores_ordenados = valores\n",
    "    print(f'\\n{col}: {valores_ordenados}')\n",
    "\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "896d4206",
   "metadata": {},
   "source": [
    "## Exclui mais algumas colunas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b07146b",
   "metadata": {},
   "source": [
    "Percebemos que as colunas a seguir, apesar de terem exemplares de muitos valores, têm sempre um valor muito dominante na categoria."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a78cea8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(['TP_NACIONALIDADE', 'TP_ESTADO_CIVIL', 'CO_PROVA_DIA1', 'CO_PROVA_DIA2', 'TP_STATUS_REDACAO'], axis=1, inplace=True)\n",
    "print(f'Total de colunas: {len(df.columns)}')\n",
    "for col in df.columns:\n",
    "    print(col)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ce32d1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import plot_barras_categoricas\n",
    "\n",
    "plot_barras_categoricas(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb43895d",
   "metadata": {},
   "source": [
    "## Aglutina mais algumas categorias"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27d555e4",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9b412ff6",
   "metadata": {},
   "source": [
    "## Analisando apenas quem foi os dois dias"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c05bebd",
   "metadata": {},
   "source": [
    "Para focar a análise e encontrar padrões relevantes, decidimos focar a análise apenas nos candidatos que foram nos dois dias."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f966b50",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import plot_barras_categoricas\n",
    "\n",
    "df_apenas_presentes = df[(df.TP_PRESENCA_DIA1 == '1') & (df.TP_PRESENCA_DIA2 == '1')].copy()\n",
    "df_apenas_presentes.drop(columns=['TP_PRESENCA_DIA2', 'TP_PRESENCA_DIA1'], inplace=True)\n",
    "print(f'Total anterior:\\t {len(df)}')\n",
    "print(f'Total novo:\\t {len(df_apenas_presentes)}')\n",
    "\n",
    "plot_barras_categoricas(df_apenas_presentes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00268a4c",
   "metadata": {},
   "source": [
    "## Analisando apenas quem faltou pelo menos um dia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c25a8df",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import plot_barras_categoricas\n",
    "\n",
    "df_apenas_presentes = df[(df.TP_PRESENCA_DIA1 != '1') | (df.TP_PRESENCA_DIA2 != '1')].copy()\n",
    "# df_apenas_presentes.drop(columns=['TP_PRESENCA_DIA2', 'TP_PRESENCA_DIA1'], inplace=True)\n",
    "print(f'Total anterior:\\t {len(df)}')\n",
    "print(f'Total novo:\\t {len(df_apenas_presentes)}')\n",
    "\n",
    "plot_barras_categoricas(df_apenas_presentes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37a0c5ab",
   "metadata": {},
   "source": [
    "## Apenas não treineiros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55ef5808",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import plot_barras_categoricas\n",
    "\n",
    "df_apenas_nao_treineiros = df[(df.IN_TREINEIRO == '0')].copy()\n",
    "df_apenas_nao_treineiros.drop(columns=['IN_TREINEIRO'], inplace=True)\n",
    "print(f'Total anterior:\\t {len(df)}')\n",
    "print(f'Total novo:\\t {len(df_apenas_nao_treineiros)}')\n",
    "\n",
    "plot_barras_categoricas(df_apenas_nao_treineiros)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4b9a445",
   "metadata": {},
   "source": [
    "## Apenas treineiros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad311374",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import plot_barras_categoricas\n",
    "\n",
    "df_apenas_treineiros = df[(df.IN_TREINEIRO == '1')].copy()\n",
    "df_apenas_treineiros.drop(columns=['IN_TREINEIRO'], inplace=True)\n",
    "print(f'Total anterior:\\t {len(df)}')\n",
    "print(f'Total novo:\\t {len(df_apenas_treineiros)}')\n",
    "\n",
    "plot_barras_categoricas(df_apenas_treineiros)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
